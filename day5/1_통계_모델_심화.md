# 통계 모델 심화

통계 모델 심화를 주제로 **ARIMA, SARIMA** 모델의 개념과 이를 **딥러닝(Attention-LSTM) 모델과 비교** 하여 알아보겠습니다.

---

## 1. ARIMA 모델 개념 (AutoRegressive Integrated Moving Average)

ARIMA는 시계열 데이터의 **과거 값과 과거의 오차**를 사용하여 미래를 예측하는 대표적인 통계 모델입니다.

---

### 1. ARIMA의 3가지 핵심 구성 요소

ARIMA는 이름에서 알 수 있듯이 세 가지 모델이 결합된 형태입니다.

#### ① AR (AutoRegressive, 자기회귀)

* **개념**: '나 자신의 과거가 미래를 결정한다'는 뜻입니다.
* **원리**: 현재 시점의 데이터를 이전 시점($t-1, t-2, ...$) 데이터들의 선형 결합으로 설명합니다.
* **의미**: 데이터에 관성이 있어서, 과거의 추세가 앞으로도 지속될 것이라고 가정할 때 효과적입니다.

#### ② I (Integrated, 차분)

* **개념**: 비정상성(Non-stationary) 데이터를 정상성(Stationary) 데이터로 바꾸는 과정입니다.
* **원리**: 현재 값에서 이전 값을 빼주는 '차분(Differencing)'을 수행합니다.
* **중요성**: 시계열 데이터가 시간에 따라 평균이나 분산이 변하면(예: 우상향하는 항공객 데이터) 통계적 예측이 어렵습니다. 차분은 이러한 트렌드를 제거하여 모델이 순수한 '변동 패턴'에 집중하게 돕습니다.

#### ③ MA (Moving Average, 이동평균)

* **개념**: '과거의 오차가 미래를 결정한다'는 뜻입니다.
* **원리**: 현재 시점의 데이터를 과거의 예측 오차(Error)들의 선형 결합으로 설명합니다.
* **의미**: 예기치 못한 사건(Shock)이 발생했을 때, 그 영향이 시간이 지남에 따라 어떻게 감소하는지를 반영합니다.

---

### 2. ARIMA(p, d, q) 파라미터의 이해

ARIMA 모델을 설정할 때 가장 중요한 것은 $(p, d, q)$라는 세 가지 숫자를 결정하는 것입니다.

* **p (AR 차수)**: 몇 단계 전의 과거까지 볼 것인가?
* **d (차분 횟수)**: 데이터를 몇 번이나 빼야 안정적인 상태가 되는가? (보통 1~2회)
* **q (MA 차수)**: 몇 단계 전의 오차까지 반영할 것인가?

---

### 3. ARIMA 모델의 한계와 극복

ARIMA는 매우 강력하지만 명확한 한계가 있습니다.

* **한계 (선형성)**: 통계 공식 기반이므로 복잡하고 비선형적인 패턴(갑작스러운 대유행 등)을 잡기 어렵습니다.
* **극복 (딥러닝과의 결합)**: 이를 해결하기 위해 최근에는 ARIMA로 데이터의 선형적인 트렌드를 먼저 잡고, 남은 복잡한 오차 패턴을 **Attention-LSTM** 같은 딥러닝 모델로 해결하는 하이브리드 방식이 많이 사용됩니다.

## 2. SARIMA 모델 이해 (Seasonal ARIMA)

ARIMA는 데이터의 전반적인 흐름은 잘 잡지만, 특정 계절마다 반복되는 패턴(계절성)을 처리하는 데 한계가 있습니다. 이를 보완한 것이 **SARIMA** 입니다.

**SARIMA(Seasonal Autoregressive Integrated Moving Average)** 는 앞서 설명해 드린 ARIMA 모델에 **'계절성(Seasonality)'** 을 처리하는 기능을 추가한 모델입니다.

항공기 승객 데이터처럼 12개월 주기로 유사한 패턴이 반복되는 시계열 데이터를 다룰 때 ARIMA보다 훨씬 강력한 성능을 발휘합니다.

---

### 1. SARIMA의 구성 요소: $(p, d, q) \times (P, D, Q)_s$

SARIMA 모델은 두 부분의 파라미터 조합으로 정의됩니다.

* **비계절성 파라미터  $(p, d, q)$**: 일반적인 ARIMA와 동일하게 데이터의 전반적인 추세와 관성을 제어합니다.
* **계절성 파라미터 $(P, D, Q)_s$**: 계절적 주기를 바탕으로 한 AR, I, MA 성분입니다.
* **$s$ (Seasonal Period)**: 계절성의 주기입니다. 항공 데이터의 경우 $s=12$(12개월)가 됩니다.
* **$P$ (Seasonal AR)**: 작년 동월($t-12$)의 값이 현재에 미치는 영향입니다.
* **$D$ (Seasonal I)**: 계절적 변동을 없애기 위해 현재 값에서 작년 동월 값을 빼는 **계절성 차분**입니다.
* **$Q$ (Seasonal MA)**: 작년 동월의 예측 오차가 현재에 미치는 영향입니다.

---

### 2. 계절성 차분(Seasonal Differencing)의 역할

SARIMA에서 가장 중요한 개념은 데이터 전처리 과정에서 보았던 **계절성 차분** 입니다.

* **왜 하는가?**: 일반적인 차분(1개월 전과 비교)은 전체적인 상승 추세는 지울 수 있지만, "매년 여름에 높고 겨울에 낮다"는 고유의 패턴은 지우지 못합니다.
* **작동 원리**: 이전 코드에서도 `passengers[12:] - passengers[:-12]`를 통해 현재 승객 수에서 1년 전 승객 수를 뺐습니다. 이렇게 하면 매년 반복되는 산 모양의 그래프가 평탄해지며 모델이 학습하기 쉬운 '정상성' 상태가 됩니다.

---

### 3. 딥러닝 모델(Attention-LSTM)과의 관계

* **차분 기법 활용**: SARIMA의 핵심인 '계절성 차분'을 통해 데이터의 복잡성을 미리 제거했습니다.
* **Attention의 역할**: SARIMA는 수식에 의해 지점을 고정적으로 보지만, **Attention 메커니즘**은 12개월의 시퀀스 중 어떤 시점이 이번 달 예측에 가장 중요한지(예: 작년 동월 혹은 지지난달 등)를 스스로 판단하여 가중치를 둡니다.
* **결론**: SARIMA는 정해진 통계 규칙을 따르고, Attention-LSTM은 그 규칙을 포함하여 더 유연하고 복잡한 패턴까지 학습합니다.

---

## 3. 딥러닝 모델(Attention-LSTM)과 통계 모델 비교

| 비교 항목 | 통계 모델 (ARIMA/SARIMA) | 딥러닝 모델 (Attention-LSTM) |
| --- | --- | --- |
| **핵심 원리** | 수학적 공식 및 통계적 가설 기반 | 데이터로부터 복잡한 패턴 직접 학습 |
| **데이터 요구량** | 적은 양의 데이터로도 구축 가능 | 대량의 데이터가 있어야 고성능 발휘 |
| **복잡한 패턴** | 선형적인 패턴 위주로 잘 잡음 | 비선형적이고 복잡한 패턴 추종에 유리 |
| **Attention 활용** | 모든 과거 데이터를 공식에 따라 처리 | 중요 시점(예: 작년 동월)에 집중하여 가중치 부여 |
| **특이사항** | 모델 파라미터 해석이 쉬움 | '차분' 기법 등을 통해 성능 극대화 가능 |

---
