# Household ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡(day5/step2 í´ë” ì°¸ì¡°)

ê°€ì •ìš© ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ëŠ” ë°ì´í„° ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ê¸°ì´ˆ, ì‹œê³„ì—´ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³ , ì „ë ¥ ì†Œë¹„ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì˜ˆì œ ì¤‘ì‹¬ìœ¼ë¡œ ì•Œì•„ ë³´ê² ìŠµë‹ˆë‹¤.

---

## 1. ë°ì´í„°ì…‹ ì¤€ë¹„ (Dataset)

* **ì¶”ì²œ ë°ì´í„°:** [UCI Machine Learning Repository - Individual household electric power consumption](https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption)
* **íŠ¹ì§•:** í”„ë‘ìŠ¤ íŒŒë¦¬ ì£¼ë³€ 7Kmì˜ í•œ ê°€êµ¬ ë‚´ì—ì„œ 47ê°œì›” ë™ì•ˆ 1ë¶„ ë‹¨ìœ„ë¡œ ì¸¡ì •ëœ ì „ë ¥ ì†Œë¹„ëŸ‰ ë°ì´í„°ì…ë‹ˆë‹¤.
* **ì£¼ìš” ë³€ìˆ˜:** ì „ì••(Voltage), ì „ë¥˜(Global_intensity), ê°€ì „ì œí’ˆë³„ ì „ë ¥(Sub_metering 1, 2, 3) ë“±.

|ë³€ìˆ˜ ì´ë¦„|ì—­í• |ìœ í˜•|ì„¤ëª…|ë‹¨ìœ„|ëˆ„ë½ëœ ê°’|
|---|---|---|---|---|---|
|Date|íŠ¹ì§•|ë‚ ì§œ|ë‚ ì§œ|ì•„ë‹ˆìš”|
|Time|íŠ¹ì§•|Categorical|ì‹œê°„| |ì•„ë‹ˆìš”|
|Global_active_power|íŠ¹ì§•|Continuous|ìœ íš¨ ì „ë ¥| |ì•„ë‹ˆìš”|
|Global_reactive_power|íŠ¹ì§•|Continuous|ë¬´íš¨ ì „ë ¥| |ì•„ë‹ˆìš”|
|Voltage|íŠ¹ì§•|Continuous|ì „ì••| |ì•„ë‹ˆìš”|
|Global_intensity|íŠ¹ì§•|Continuous|ì´ ì „ë¥˜ ì„¸ê¸°|ì•„ë‹ˆìš”|
|Sub_metering_1|íŠ¹ì§•|Continuous|ì£¼ë°©| |ì•„ë‹ˆìš”|
|Sub_metering_2|íŠ¹ì§•|Continuous|ì„¸íƒì‹¤| |ì•„ë‹ˆìš”|
|Sub_metering_3íŠ¹ì§•|Continuous|ëƒ‰ë‚œë°©| |ì•„ë‹ˆìš”|

---

## 2. í”„ë¡œì íŠ¸ íŒŒì´í”„ë¼ì¸

ì—ë„ˆì§€ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ëŠ” ì•„ë˜ì˜ íë¦„ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

1. **ë°ì´í„° ì „ì²˜ë¦¬:** ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ë‚ ì§œ/ì‹œê°„ ë°ì´í„° ë³€í™˜.
2. **íŠ¹ì„± ê³µí•™(Feature Engineering):** ì‹œê°„ëŒ€(ì˜¤ì „/ì˜¤í›„), ìš”ì¼(ì£¼ë§ ì—¬ë¶€), ê³„ì ˆì„± ë³€ìˆ˜ ìƒì„±.
3. **ëª¨ë¸ë§:** ARIMA ëª¨ë¸ë§ ë˜ëŠ” ì‹œê³„ì—´ ëª¨ë¸(LSTM)
4. **ì˜ˆì¸¡:** 1ë‹¬ í›„ ì˜ˆì¸¡.

---

## 3. Python ì‹¤ì „ ì½”ë“œ ì˜ˆì œ

### 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ

[UCI Machine Learning Repository - Individual household electric power consumption](https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption)
ì—ì„œ ì••ì¶•ëœ ìë£Œë¥¼ ë‹¤ìš´ë°›ì•„ ./data í´ë”ì— ì••ì¶•ì„ í‘¸ì„¸ìš”.

### 2. ë°ì´í„° ì „ì²˜ë¦¬

UCI ë°ì´í„°ì…‹ì€ 1ë¶„ ë‹¨ìœ„ë¡œ ê¸°ë¡ëœ ë§¤ìš° ë°©ëŒ€í•œ ë°ì´í„°(ì•½ 200ë§Œ í–‰)ì´ë¯€ë¡œ, ì´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì½ì–´ì™€ì„œ ì¼ë‹¨ìœ„(Daily)ë¡œ ìš”ì•½(Resampling)í•˜ëŠ” ê³¼ì •ì´ í”„ë¡œì íŠ¸ì˜ ì²« ë‹¨ì¶”ì…ë‹ˆë‹¤.

íŠ¹íˆ ë©”ëª¨ë¦¬ ì ˆì•½ê³¼ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ì— ìœ ì˜í•˜ì—¬ ì½”ë“œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

ì‘ì—…ìˆœì„œ

1. ë°ì´í„° ì½ê¸°
2. ë‚ ì§œì™€ ì‹œê°„ ì»¬ëŸ¼ì„ í•©ì¹¨
3. ì¸ë±ìŠ¤ ì„¤ì • ë° ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì‚­ì œ
4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ìˆ«ìí˜• ë³€í™˜
5. ì¼ë‹¨ìœ„ ì¬ìƒ˜í”Œë§
6. ê²°ê³¼ í™•ì¸ ë° ì €ì¥

íŒŒì¼ëª… : day5/step2/household_resample.py

```python
import pandas as pd
import numpy as np

# 1. ë°ì´í„° ì½ê¸°
# - sep=';' : ë°ì´í„°ê°€ ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŒ
# - low_memory=False : ë°ì´í„° íƒ€ì… ì¶”ë¡  ì‹œ ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ ë¹„í™œì„±í™”
# - na_values=['?'] : ë°ì´í„° ì¤‘ '?'ë¡œ í‘œì‹œëœ ê²°ì¸¡ì¹˜ë¥¼ NaNìœ¼ë¡œ ì¸ì‹
file_path = './data/household_power_consumption.txt'

print("ë°ì´í„°ë¥¼ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")

# 1. ì¼ë‹¨ ì»¬ëŸ¼ë³„ë¡œ ì½ì–´ì˜¤ê¸°
df = pd.read_csv(file_path, sep=';', 
                 low_memory=False, 
                 na_values=['?'])

# 2. ë‚ ì§œì™€ ì‹œê°„ ì»¬ëŸ¼ì„ í•©ì³ì„œ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜
# Dateì™€ Time ì»¬ëŸ¼ì„ í•©ì³ì„œ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
df['dt'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], dayfirst=True)

# 3. ì¸ë±ìŠ¤ ì„¤ì • ë° ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì‚­ì œ
df.set_index('dt', inplace=True)
df.drop(['Date', 'Time'], axis=1, inplace=True)

# 4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ìˆ«ìí˜• ë³€í™˜
df = df.ffill().astype(float)

# 5. ì¼ë‹¨ìœ„ ì¬ìƒ˜í”Œë§ (Resampling)
# 'D'ëŠ” Dayë¥¼ ì˜ë¯¸í•˜ë©°, í•˜ë£¨ ë™ì•ˆì˜ í•©ê³„(sum)ë¥¼ êµ¬í•¨
# ë§Œì•½ í•˜ë£¨ í‰ê·  ì‚¬ìš©ëŸ‰ì„ ì•Œê³  ì‹¶ë‹¤ë©´ .mean()ì„ ì‚¬ìš©í•˜ì„¸ìš”.
df_daily = df.resample('D').sum()

# 6. ê²°ê³¼ í™•ì¸
print("\n--- ì¬ìƒ˜í”Œë§ ì™„ë£Œ ---")
print(df_daily.head())
print(f"\në°ì´í„° í¬ê¸° ë³€í™˜: {df.shape[0]} í–‰ -> {df_daily.shape[0]} í–‰")

# 7. ì €ì¥ 
df_daily.to_csv('./data/household_daily_usage.csv')
```

SARIMA ëª¨ë¸ ì ìš©í•˜ì—¬ í•™ìŠµí•˜ì—¬ ìµœì¢… 30ì¼ ì´ì „ ìë£Œì™€ ë¹„êµ

íŒŒì¼ëª… : day5/step2/household1.py

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from pmdarima import auto_arima

file_path = './data/household_daily_usage.csv'
# 1. ì¼ë‹¨ ì»¬ëŸ¼ë³„ë¡œ ì½ì–´ì˜¤ê¸°
df = pd.read_csv(file_path, parse_dates=['dt'], index_col='dt')

# 2. ë°ì´í„° ë¶„í•´ (seasonal_decompose)
# ë°ì´í„°ì˜ êµ¬ì„± ìš”ì†Œ: Trend(ì¶”ì„¸), Seasonal(ê³„ì ˆì„±), Resid(ì”ì°¨) í™•ì¸
print("ë°ì´í„° ë¶„í•´ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
result = seasonal_decompose(df['Global_active_power'], model='additive', period=7) # ì£¼ê°„ ì£¼ê¸°(7ì¼) ê°€ì •

result.plot()
plt.show()

# 3. ìµœì ì˜ ARIMA íŒŒë¼ë¯¸í„° ì°¾ê¸° (auto_arima)
# p, d, që¥¼ ìˆ˜ë™ìœ¼ë¡œ ì •í•˜ì§€ ì•Šê³  ëª¨ë¸ì´ ë°ì´í„°ì— ë§ì¶° ìµœì ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
print("ìµœì ì˜ ARIMA íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
stepwise_model = auto_arima(df['Global_active_power'], 
                            m=7,                # ì£¼ê°„ ê³„ì ˆì„± ë°˜ì˜
                            seasonal=True,      # SARIMA ì‚¬ìš©
                            stepwise=True,      # ìµœì í™” ì†ë„ í–¥ìƒ
                            trace=False         # ì¤‘ê°„ ê³¼ì • ì¶œë ¥ ìƒëµ (ë” ê¹”ë”í•¨)
                            )

print(stepwise_model.summary())

# 4. í•™ìŠµ ë° ë¯¸ë˜ ì˜ˆì¸¡
# ë§ˆì§€ë§‰ 30ì¼ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬
train = df['Global_active_power'][:-30]
test = df['Global_active_power'][-30:]

stepwise_model.fit(train)

# 30ì¼ì¹˜ ì˜ˆì¸¡
future_forecast = stepwise_model.predict(n_periods=30)

# [4ë‹¨ê³„] ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 6))
plt.plot(test.index, test.values, label='Actual')
plt.plot(test.index, future_forecast, label='Auto-ARIMA Prediction', color='red')
plt.title('Energy Consumption Prediction with Auto-ARIMA')
plt.legend()
plt.show()
```

ì‹¤í–‰ê²°ê³¼

![alt text](image-3.png)

---

### 3. íŠ¹ì„± ê³µí•™ (Feature Engineering)

ì¸ë±ìŠ¤(ë‚ ì§œ)ì—ì„œ ìš”ì¼ì„ ì¶”ì¶œ (5: í† ìš”ì¼, 6: ì¼ìš”ì¼)

```python
df['is_weekend'] = df.index.dayofweek.map(lambda x: 1 if x >= 5 else 0)
```

## 4. í”„ë¡œì íŠ¸ ê³ ë„í™” íŒ

ë‹¨ìˆœíˆ "ì—ë„ˆì§€ë¥¼ ë§ì´ ì“´ë‹¤"ë¥¼ ë§íˆëŠ” ê²ƒë³´ë‹¤, **"ì™œ ë§ì´ ì¼ëŠ”ê°€"** ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì´ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„  ë” ì¤‘ìš”í•©ë‹ˆë‹¤.

* **ì™¸ë¶€ ë°ì´í„° ê²°í•©:** ê¸°ìƒì²­ APIë¥¼ í†µí•´ 'ë¶ˆì¾Œì§€ìˆ˜'ë‚˜ 'í­ì—¼ì£¼ì˜ë³´' ë°ì´í„°ë¥¼ ê²°í•©í•´ì„œ í•™ìŠµì„ ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ì§€ì—° ë³€ìˆ˜(Lag Features):** "ì–´ì œì˜ ì‚¬ìš©ëŸ‰"ì€ "ì˜¤ëŠ˜ì˜ ì‚¬ìš©ëŸ‰"ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ê°€ì¥ ê°•ë ¥í•œ íŒíŠ¸ê°€ ë©ë‹ˆë‹¤. `df['target_usage'].shift(1)`ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”.

---
**Meteostat** ëŠ” ì „ ì„¸ê³„ì˜ ê¸°ìƒ ê´€ì¸¡ì†Œ ë°ì´í„°ë¥¼ ì•„ì£¼ ì‰½ê³  ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì•ì„œ `./data/paris_weather_data.csv` íŒŒì¼ì„ ì§ì ‘ ë¡œë”©í–ˆë˜ ì‘ì—…ì„, ì´ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ **ì½”ë“œ ëª‡ ì¤„ë¡œ ì „ ì„¸ê³„ ì–´ë””ë“  ì‹¤ì‹œê°„ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê¸ì–´ì˜¤ëŠ” ì‘ì—…**ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë°ì´í„° ê³¼í•™ìë“¤ì´ ê¸°ìƒ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ê°€ì¥ ì„ í˜¸í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

---

## 5. Meteostatì„ ì´ìš©í•˜ì—¬ ê¸°ìƒì •ë³´ ì–»ê¸°

**Meteostat** ëŠ” ì „ ì„¸ê³„ì˜ ê¸°ìƒ ê´€ì¸¡ì†Œ ë°ì´í„°ë¥¼ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì´ìš©í•  ìˆ˜ ìˆë„ë¡ ì œê³µí•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ê¸°ìƒ ë°ì´í„° ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ì í”Œë«í¼ì…ë‹ˆë‹¤.

* **ë°©ëŒ€í•œ ë°ì´í„° ì†ŒìŠ¤:** NOAA(ë¯¸êµ­ í•´ì–‘ëŒ€ê¸°ì²­), ë…ì¼ ê¸°ìƒì²­ ë“± ê³µì‹ ë ¥ ìˆëŠ” ê¸°ê´€ì˜ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.
* **ìœ ì—°í•œ ì‹œê°„ ë‹¨ìœ„:** **ì‹œê°„ ë‹¨ìœ„(Hourly)**, **ì¼ ë‹¨ìœ„(Daily)**, **ì›” ë‹¨ìœ„(Monthly)** ë°ì´í„°ë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
* **ìë™ ë³´ê°„:** íŠ¹ì • ê´€ì¸¡ì†Œì— ë°ì´í„°ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì¸ê·¼ ê´€ì¸¡ì†Œì˜ ë°ì´í„°ë¥¼ í™œìš©í•´ ìë™ìœ¼ë¡œ ì±„ì›Œì£¼ëŠ” ê¸°ëŠ¥ì´ ê°•ë ¥í•©ë‹ˆë‹¤.
* **Pandas ì¹œí™”ì :** ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë©´ ì¦‰ì‹œ `Pandas DataFrame` í˜•íƒœë¡œ ë°˜í™˜ë©ë‹ˆë‹¤

íŒŒì¼ëª… : day5/step2/paris_weather.py

```python
from datetime import datetime
from meteostat import daily

# íŒŒë¦¬ì˜ ê¸°ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤.

# 1. ê¸°ê°„ ì„¤ì • (2006-12-01 ~ 2010-11-26)
start = datetime(2006, 12, 16)
end = datetime(2010, 11, 26)

# 2. ì¼ ë‹¨ìœ„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ê´€ì¸¡ì†Œ IDë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° í˜¸ì¶œ (07149ëŠ” íŒŒë¦¬ ì˜¤ë¥¼ë¦¬ ê³µí•­)
data = daily('07149', start, end)
data = data.fetch()

# 3. ê²°ê³¼ í™•ì¸ (ê¸°ì˜¨, ê°•ìˆ˜ëŸ‰ ë“±)
print(data.head())

data.to_csv('./data/paris_weather_data.csv')
```

### ì œê³µë˜ëŠ” ì£¼ìš” ì»¬ëŸ¼ ì •ë³´

| ì»¬ëŸ¼ëª… | í•œê¸€ ì„¤ëª… | ë‹¨ìœ„ | ì—ë„ˆì§€ ì˜ˆì¸¡ ì‹œ í™œìš© íŒ |
| --- | --- | --- | --- |
| **time** | ê´€ì¸¡ ì‹œê°„ | ì¼/ì‹œ | ì£¼ê¸°ì„±(ì‹œê°„ëŒ€, ìš”ì¼, ê³„ì ˆ)ì„ íŒŒì•…í•˜ëŠ” ê¸°ì¤€ì ì…ë‹ˆë‹¤. |
| **temp** | í‰ê·  ê¸°ì˜¨ | Â°C | **ê°€ì¥ ì¤‘ìš”.** ëƒ‰/ë‚œë°© ì „ë ¥ ì‚¬ìš©ëŸ‰ê³¼ ì§ê²°ë©ë‹ˆë‹¤. |
| **tmin** | ìµœì € ê¸°ì˜¨ | Â°C | ì•¼ê°„ ë° ìƒˆë²½ ì‹œê°„ëŒ€ì˜ ë‚œë°© ìˆ˜ìš”ë¥¼ ì˜ˆì¸¡í•  ë•Œ ì“°ì…ë‹ˆë‹¤. |
| **tmax** | ìµœê³  ê¸°ì˜¨ | Â°C | ë‚® ì‹œê°„ëŒ€ í­ì—¼ìœ¼ë¡œ ì¸í•œ ì—ì–´ì»¨ ì‚¬ìš© ê¸‰ì¦ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. |
| **rhum** | ìƒëŒ€ ìŠµë„ | % | ê¸°ì˜¨ê³¼ ê²°í•©í•˜ì—¬ **ë¶ˆì¾Œì§€ìˆ˜**ë¥¼ ê³„ì‚°í•  ë•Œ í•„ìˆ˜ì…ë‹ˆë‹¤. |
| **prcp** | ê°•ìˆ˜ëŸ‰ | mm | ë¹„ê°€ ì˜¤ë©´ ì™¸ë¶€ í™œë™ì´ ì¤„ì–´ ê°€ì „ì œí’ˆ ì‚¬ìš©ëŸ‰ì´ ëŠ˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤. |
| **snwd** | ì ì„¤ëŸ‰ | mm | í­ì„¤ ì‹œ ì™¸ë¶€ í™œë™ ì œí•œ ë° ë‚œë°© ìˆ˜ìš” í­ì¦ì˜ ì§€í‘œê°€ ë©ë‹ˆë‹¤. |
| **wspd** | í‰ê·  í’ì† | km/h | ë°”ëŒì´ ê°•í•˜ë©´ ì²´ê° ì˜¨ë„ê°€ ë‚®ì•„ì ¸ ë‚œë°© ë¶€í•˜ê°€ ì»¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. |
| **wpgt** | ìµœëŒ€ ìˆœê°„ í’ì† | km/h | ì´ìƒ ê¸°í›„ë‚˜ íƒœí’ ë“±ì˜ íŠ¹ì´ ì¼€ì´ìŠ¤ ë¶„ì„ì— í™œìš©ë©ë‹ˆë‹¤. |
| **pres** | í•´ë©´ ê¸°ì•• | hPa | ê¸°ì•• ë³€í™”ëŠ” ë‚ ì”¨ ë³€í™”ì˜ ì „ì¡° ì¦ìƒìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤. |
| **tsun** | ì¼ì¡° ì‹œê°„ | ë¶„(min) | íƒœì–‘ê´‘ ë°œì „ëŸ‰ì´ ìˆëŠ” ê°€êµ¬ì˜ ê²½ìš° ìˆœ ì „ë ¥ ìˆ˜ìš”ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤. |
| **cldc** | í´ë¼ìš°ë“œ ì»¤ë²„ (ìš´ëŸ‰) | % | êµ¬ë¦„ì´ ë§ìœ¼ë©´ ì¼ì‚¬ëŸ‰ì´ ì¤„ì–´ ë‚® ì‹œê°„ ì¡°ëª… ì‚¬ìš©ëŸ‰ì´ ëŠ˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤. |

## 6. ê¸°ìƒì •ë³´ì™€ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„° ê²°í•©

1. ë°ì´í„° ë¡œë”©

```bash
# ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„° ì½ê¸°
df_energy = pd.read_csv('./data/household_daily_usage.csv', parse_dates=['dt'], index_col='dt')
# ê¸°ìƒì •ë³´ ë°ì´í„° ì½ê¸°
df_weather = pd.read_csv('./data/paris_weather_data.csv', parse_dates=['time'], index_col='time')
```

2. ë°ì´í„° ë³‘í•©

```bash
# ë°ì´í„° ë³‘í•©
df = df_energy.join(df_weather, how='inner')
```

3. ê¸°ìƒì •ë³´ì™€ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„° ê²°í•©í•˜ì—¬ SARIMAX ëª¨ë¸ í•™ìŠµ

íŒŒì¼ëª… : day5/step2/household2_weater.py

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pmdarima import auto_arima

# [1] ë°ì´í„° ë¡œë”© (ê¸°ì¡´ê³¼ ë™ì¼)
df_energy = pd.read_csv('./data/household_daily_usage.csv', parse_dates=['dt'], index_col='dt')
df_weather = pd.read_csv('./data/paris_weather_data.csv', parse_dates=['time'], index_col='time')

# [2] ë‚ ì”¨ ë°ì´í„° ì „ì²˜ë¦¬ + í‰ê· ì˜¨ë„ ê³„ì‚°
weather_cols = ['tmin', 'tmax', 'prcp']
df_weather = df_weather[weather_cols].copy()
df_weather['temp_est'] = (df_weather['tmin'] + df_weather['tmax']) / 2
df_weather = df_weather.interpolate().ffill().bfill()

# [3] ë°ì´í„° ë³‘í•©
df = df_energy.join(df_weather, how='inner')

# [4] ì£¼ë§ ì—¬ë¶€(is_weekend) ë³€ìˆ˜ ì¶”ê°€ (í•µì‹¬!)
# ì¸ë±ìŠ¤(ë‚ ì§œ)ì—ì„œ ìš”ì¼ì„ ì¶”ì¶œ (5: í† ìš”ì¼, 6: ì¼ìš”ì¼)
df['is_weekend'] = df.index.dayofweek.map(lambda x: 1 if x >= 5 else 0)

# [5] ë¶„ì„ ë°ì´í„° ì¤€ë¹„
y = df['Global_active_power']
# ì™¸ìƒ ë³€ìˆ˜ì— ì£¼ë§ ì—¬ë¶€ ì¶”ê°€
X = df[['temp_est', 'tmin', 'tmax', 'prcp', 'is_weekend']]

# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
train_y, test_y = y[:-30], y[-30:]
train_X, test_X = X[:-30], X[-30:]

# [6] SARIMAX ëª¨ë¸ í•™ìŠµ
print("ë‚ ì”¨ì™€ ì£¼ë§ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤...")
stepwise_model = auto_arima(train_y, 
                            X=train_X, 
                            m=7, 
                            seasonal=True, 
                            stepwise=True, 
                            trace=True)

# [7] ì˜ˆì¸¡ ë° ì‹œê°í™”
future_forecast = stepwise_model.predict(n_periods=30, X=test_X)

plt.figure(figsize=(12, 6))
plt.plot(test_y.index, test_y.values, label='Actual', color='blue')
plt.plot(test_y.index, future_forecast, label='SARIMAX + Weather + Weekend', color='green', linestyle='--')
plt.title('Energy Prediction with Weather & Weekend Factor')
plt.legend()
plt.show()
```

ì‹¤í–‰ê²°ê³¼
![alt text](image-4.png)

4. LSTM ëª¨ë¸ í•™ìŠµ

íŒŒì¼ëª… : day5/step2/household3_lstm.py

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping

# [1] ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# - ì´ì „ ë‹¨ê³„ì™€ ë™ì¼í•˜ê²Œ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê³¼ ë‚ ì”¨ ë°ì´í„°ë¥¼ ê²°í•©í•˜ê³  ì£¼ë§ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
df_energy = pd.read_csv(r'.\data\household_daily_usage.csv', parse_dates=['dt'], index_col='dt')
df_weather = pd.read_csv(r'.\data\paris_weather_data.csv', parse_dates=['time'], index_col='time')

df_weather['temp_est'] = (df_weather['tmin'] + df_weather['tmax']) / 2
df_weather = df_weather[['temp_est', 'tmin', 'tmax', 'prcp']].interpolate().ffill().bfill()
df = df_energy.join(df_weather, how='inner')
df['is_weekend'] = df.index.dayofweek.map(lambda x: 1 if x >= 5 else 0)

# [2] í•™ìŠµ íŠ¹ì„±(Features) ì„ ì •
# - íƒ€ê²Ÿì¸ 'Global_active_power'ë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ ë‘ì–´, ì´í›„ ì—­ìŠ¤ì¼€ì¼ë§(ì›ë˜ ê°’ ë³µì›) ì‹œ í¸ë¦¬í•˜ê²Œ êµ¬ì„±í•©ë‹ˆë‹¤.
features = ['Global_active_power', 'temp_est', 'tmin', 'tmax', 'prcp', 'is_weekend']
dataset = df[features].values

# [3] ë°ì´í„° ì •ê·œí™” (Scaling)
# - LSTMì€ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì •ê·œí™”ë˜ì—ˆì„ ë•Œ ìˆ˜ë ´ ì†ë„ì™€ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤.
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(dataset)

# [4] ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± í•¨ìˆ˜ (Window Sliding Technique)
# - ê³¼ê±° ì¼ì£¼ì¼(seq_length)ì˜ ë°ì´í„°ë¥¼ ë³´ê³  ë‹¤ìŒ ë‚ ì˜ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” í˜•íƒœë¡œ ë°ì´í„°ì…‹ì„ ë³€í˜•í•©ë‹ˆë‹¤.
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        # ië¶€í„° i+seq_lengthê¹Œì§€ì˜ 6ê°œ ë³€ìˆ˜ ë°ì´í„°ë¥¼ ì…ë ¥(X)ìœ¼ë¡œ ì‚¬ìš©
        X.append(data[i:i+seq_length, :]) 
        # i+seq_length ì‹œì ì˜ ì²« ë²ˆì§¸ ì»¬ëŸ¼(ì „ë ¥ ì‚¬ìš©ëŸ‰)ì„ ì •ë‹µ(y)ìœ¼ë¡œ ì‚¬ìš©
        y.append(data[i+seq_length, 0])    
    return np.array(X), np.array(y)

seq_length = 7 # ê³¼ê±° 7ì¼ì¹˜ë¥¼ í•™ìŠµí•˜ì—¬ 8ì¼ì§¸ë¥¼ ì˜ˆì¸¡
X, y = create_sequences(scaled_data, seq_length)

# [5] í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„ë¦¬
# - ìˆœì„œê°€ ì¤‘ìš”í•œ ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ ëœë¤ ì…”í”Œë§ ì—†ì´ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë§ˆì§€ë§‰ 30ì¼ì„ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
train_size = len(X) - 30
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# [6] LSTM ì‹ ê²½ë§ ëª¨ë¸ ì„¤ê³„
# - LSTM ê³„ì¸µ: ì‹œê³„ì—´ì˜ ì¥ë‹¨ê¸° ê¸°ì–µì„ ë‹´ë‹¹
# - Dropout: ê³¼ì í•©(Overfitting)ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¬´ì‘ìœ„ë¡œ ì¼ë¶€ ë‰´ëŸ°ì„ ë”
# - Dense(1): ìµœì¢…ì ìœ¼ë¡œ ë‹¤ìŒ ë‚ ì˜ ì „ë ¥ëŸ‰ 1ê°œë¥¼ ì˜ˆì¸¡
model = Sequential([
    # ì…ë ¥ ê·œê²© ì •ì˜: (7ì¼ì˜ íƒ€ì„ìŠ¤í…, 6ê°œì˜ íŠ¹ì„±)
    Input(shape=(X_train.shape[1], X_train.shape[2])),
    
    # ì²« ë²ˆì§¸ LSTM ê³„ì¸µ: return_sequences=TrueëŠ” ë‹¤ìŒ LSTM ì¸µìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•¨
    LSTM(128, return_sequences=True),
    Dropout(0.2),
    
    # ë‘ ë²ˆì§¸ LSTM ê³„ì¸µ: return_sequences=FalseëŠ” ì‹œí€€ìŠ¤ë¥¼ ìš”ì•½í•˜ì—¬ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë§Œë“¦
    LSTM(64, return_sequences=False),
    Dropout(0.2),
    
    # ì¶œë ¥ ê³„ì¸µ: ë‹¤ìŒ ë‚ ì˜ ì „ë ¥ ì‚¬ìš©ëŸ‰ 1ê°œ ì˜ˆì¸¡
    Dense(1) 
])

# [7] ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ
model.compile(optimizer='adam', loss='mse')

# EarlyStopping ì„¤ì •: ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë³µêµ¬í•˜ë„ë¡ restore_best_weights ì¶”ê°€ ê¶Œì¥
early_stop = EarlyStopping(
    monitor='val_loss', 
    patience=5, 
    restore_best_weights=True
)

print("ğŸš€ ë‹¤ë³€ëŸ‰ LSTM í•™ìŠµ ì‹œì‘...")
history = model.fit(
    X_train, y_train, 
    epochs=50, 
    batch_size=16, 
    validation_split=0.1, 
    callbacks=[early_stop], 
    verbose=1
)
# [8] ì˜ˆì¸¡ ë° ì—­ì •ê·œí™” (Inversing Scaling)
# - ëª¨ë¸ì€ 0~1 ì‚¬ì´ ê°’ì„ ì¶œë ¥í•˜ë¯€ë¡œ, ì´ë¥¼ ì‹¤ì œ ë‹¨ìœ„ì¸ kWë¡œ ë³µêµ¬í•´ì•¼ í•©ë‹ˆë‹¤.
predictions = model.predict(X_test)

# - ì—­ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•˜ë ¤ë©´ í•™ìŠµ ë‹¹ì‹œ ì‚¬ìš©í•œ 6ê°œ ì»¬ëŸ¼ì˜ í˜•ì‹ì„ ë§ì¶°ì•¼ í•¨ (ë”ë¯¸ í–‰ë ¬ í™œìš©)
predict_copies = np.zeros((len(predictions), len(features)))
predict_copies[:, 0] = predictions.flatten() # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ì˜ˆì¸¡ê°’ ë°°ì¹˜
inv_predictions = scaler.inverse_transform(predict_copies)[:, 0] # ì›ë˜ ë‹¨ìœ„ë¡œ ë³µì›

# - ì‹¤ì œ ê°’(y_test)ë„ ë¹„êµë¥¼ ìœ„í•´ ë™ì¼í•˜ê²Œ ì—­ìŠ¤ì¼€ì¼ë§ ì§„í–‰
actual_copies = np.zeros((len(y_test), len(features)))
actual_copies[:, 0] = y_test
inv_actual = scaler.inverse_transform(actual_copies)[:, 0]

# [9] ìµœì¢… ê²°ê³¼ ì‹œê°í™” ë° ë¹„êµ
plt.figure(figsize=(12, 6))
plt.plot(df.index[-30:], inv_actual, label='Actual (ì‹¤ì œ)', color='blue', marker='o')
plt.plot(df.index[-30:], inv_predictions, label='LSTM Prediction (ì˜ˆì¸¡)', color='orange', linestyle='--', marker='s')
plt.title('Energy Consumption Prediction (LSTM)')
plt.ylabel('Global Active Power (kW)')
plt.legend()
plt.grid(True)
plt.show()

```

ì‹¤í–‰ê²°ê³¼

![alt text](image-6.png)

5. salimaxì™€ lstmì„ ê²°í•©í•˜ì—¬ ì˜ˆì¸¡

íŒŒì¼ëª… : day5/step2/household4_salimax_lstm.py

```python

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from pmdarima import auto_arima
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from sklearn.metrics import mean_squared_error

# [1] ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)
df_energy = pd.read_csv(r'.\data\household_daily_usage.csv', parse_dates=['dt'], index_col='dt')
df_weather = pd.read_csv(r'.\data\paris_weather_data.csv', parse_dates=['time'], index_col='time')

df_weather['temp_est'] = (df_weather['tmin'] + df_weather['tmax']) / 2
df_weather = df_weather[['temp_est', 'tmin', 'tmax', 'prcp']].interpolate().ffill().bfill()
df = df_energy.join(df_weather, how='inner')
df['is_weekend'] = df.index.dayofweek.map(lambda x: 1 if x >= 5 else 0)

# [2] ë°ì´í„° ë¶„ë¦¬
# - ê³µí†µ í…ŒìŠ¤íŠ¸ì…‹ êµ¬ê°„ (ë§ˆì§€ë§‰ 30ì¼)ì„ ì„¤ì •í•˜ì—¬ ë‘ ëª¨ë¸ì„ ê³µì •í•˜ê²Œ ë¹„êµí•©ë‹ˆë‹¤.
y = df['Global_active_power']
X_vars = df[['temp_est', 'tmin', 'tmax', 'prcp', 'is_weekend']]

train_y, test_y = y[:-30], y[-30:]
train_X, test_X = X_vars[:-30], X_vars[-30:]

# --- [3] ëª¨ë¸ 1: SARIMAX (í†µê³„ì  ëª¨ë¸) ---
# - í†µê³„ì  ì¶”ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œê³„ì—´ì˜ ì„ í˜•ì  íŒ¨í„´ê³¼ ê³„ì ˆì„±ì„ ì˜ í¬ì°©í•©ë‹ˆë‹¤.
print("Step 1: SARIMAX í•™ìŠµ ë° ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
sarima_model = auto_arima(train_y, X=train_X, m=7, seasonal=True, stepwise=True)
sarima_pred = sarima_model.predict(n_periods=30, X=test_X)

# --- [4] ëª¨ë¸ 2: LSTM (ë”¥ëŸ¬ë‹ ëª¨ë¸) ---
# - ì‹ ê²½ë§ì„ í†µí•´ ë°ì´í„°ì˜ ë¹„ì„ í˜•ì ì¸ ë³µì¡í•œ ê´€ê³„ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
print("Step 2: LSTM í•™ìŠµ ë° ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['Global_active_power', 'temp_est', 'tmin', 'tmax', 'prcp', 'is_weekend']])

def create_sequences(data, seq_length):
    X, target = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length, :])
        target.append(data[i+seq_length, 0])
    return np.array(X), np.array(target)

seq_length = 7
X_seq, y_seq = create_sequences(scaled_data, seq_length)

X_train_lstm = X_seq[:-30]
y_train_lstm = y_seq[:-30]
X_test_lstm = X_seq[-30:]

lstm_model = Sequential([
    Input(shape=(seq_length, X_seq.shape[2])),
    LSTM(128, return_sequences=True),
    Dropout(0.2),
    LSTM(64, return_sequences=False),
    Dense(1)
])
lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, verbose=0)

# - LSTM ì˜ˆì¸¡ ê²°ê³¼ ì—­ìŠ¤ì¼€ì¼ë§
lstm_raw_pred = lstm_model.predict(X_test_lstm)
dummy = np.zeros((30, 6))
dummy[:, 0] = lstm_raw_pred.flatten()
lstm_pred = scaler.inverse_transform(dummy)[:, 0]

# --- [5] ëª¨ë¸ ê²°í•©: Weighted Ensemble ---
# - ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ ê°€ì¤‘ í‰ê· í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ë„ì¶œí•©ë‹ˆë‹¤.
# - ì—¬ê¸°ì„œëŠ” SARIMAXì— 40%, LSTMì— 60% ë¹„ì¤‘ì„ ë‘ì–´ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ë…¸ë¦½ë‹ˆë‹¤.
print("Step 3: ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ì•™ìƒë¸” ìƒì„± ì¤‘...")
ensemble_pred = (sarima_pred.values * 0.4) + (lstm_pred * 0.6)

# [6] ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 6))
plt.plot(test_y.index, test_y.values, label='Actual (ì‹¤ì œ)', color='black', alpha=0.3)
plt.plot(test_y.index, sarima_pred, label='SARIMAX Prediction', linestyle='--', alpha=0.6)
plt.plot(test_y.index, lstm_pred, label='LSTM Prediction', linestyle='--', alpha=0.6)
plt.plot(test_y.index, ensemble_pred, label='Ensemble Result (Combined)', color='red', linewidth=2)
plt.title('SARIMAX & LSTM Ensemble Energy Prediction')
plt.legend()
plt.grid(True)
plt.show()

# [7] ì„±ëŠ¥ ì§€í‘œ í‰ê°€ (RMSE)
# - ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´ë¥¼ ìˆ˜ì¹˜ë¡œ í™•ì¸í•˜ì—¬ ì–´ë–¤ ëª¨ë¸ì´ ìš°ìˆ˜í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤. (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
print("\n--- ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (RMSE) ---")
sarima_rmse = np.sqrt(mean_squared_error(test_y, sarima_pred))
lstm_rmse = np.sqrt(mean_squared_error(test_y, lstm_pred))
ensemble_rmse = np.sqrt(mean_squared_error(test_y, ensemble_pred))

print(f"1. SARIMAX RMSE : {sarima_rmse:.4f}")
print(f"2. LSTM RMSE    : {lstm_rmse:.4f}")
print(f"3. Ensemble RMSE: {ensemble_rmse:.4f} (ìµœì¢… ëª¨ë¸)")

```

ì‹¤í–‰ê²°ê³¼

![alt text](image-7.png)

6. ì˜ˆì¸¡ì„ í•˜ê¸° ìœ„í•´ í•™ìŠµí•˜ê³  ëª¨ë¸ ì €ì¥í•˜ê¸°

íŒŒì¼ëª… : day5/step2/household5_training.py

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from pmdarima import auto_arima
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
import joblib
import os

# [1] ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)
df_energy = pd.read_csv(r'.\data\household_daily_usage.csv', parse_dates=['dt'], index_col='dt')
df_weather = pd.read_csv(r'.\data\paris_weather_data.csv', parse_dates=['time'], index_col='time')

df_weather['temp_est'] = (df_weather['tmin'] + df_weather['tmax']) / 2
df_weather = df_weather[['temp_est', 'tmin', 'tmax', 'prcp']].interpolate().ffill().bfill()
df = df_energy.join(df_weather, how='inner')
df['is_weekend'] = df.index.dayofweek.map(lambda x: 1 if x >= 5 else 0)

# [2] í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
y = df['Global_active_power']
X_vars = df[['temp_est', 'tmin', 'tmax', 'prcp', 'is_weekend']]
train_y, test_y = y[:-30], y[-30:]
train_X, test_X = X_vars[:-30], X_vars[-30:]

# --- [3] ëª¨ë¸ 1: SARIMAX í•™ìŠµ ---
print("SARIMAX ëª¨ë¸ì„ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤...")
sarima_model = auto_arima(train_y, X=train_X, m=7, seasonal=True, stepwise=True)

# --- [4] ëª¨ë¸ 2: LSTM í•™ìŠµ ---
print("LSTM ì‹ ê²½ë§ ëª¨ë¸ì„ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤...")
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['Global_active_power', 'temp_est', 'tmin', 'tmax', 'prcp', 'is_weekend']])

def create_sequences(data, seq_length):
    X, target = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length, :])
        target.append(data[i+seq_length, 0])
    return np.array(X), np.array(target)

seq_length = 7
X_seq, y_seq = create_sequences(scaled_data, seq_length)
X_train_lstm = X_seq[:-30]
y_train_lstm = y_seq[:-30]

lstm_model = Sequential([
    Input(shape=(seq_length, X_seq.shape[2])),
    LSTM(128, return_sequences=True),
    Dropout(0.2),
    LSTM(64, return_sequences=False),
    Dense(1)
])
lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, verbose=0)

# [5] ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ (Persistence)
# - í•™ìŠµëœ ê²°ê³¼ë¬¼ì„ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬, ë‚˜ì¤‘ì— ë‹¤ì‹œ í•™ìŠµí•  í•„ìš” ì—†ì´ ë°”ë¡œ ì˜ˆì¸¡(Inference)ì— í™œìš©í•©ë‹ˆë‹¤.
if not os.path.exists('./model'):
    os.makedirs('./model')

print("\n--- ëª¨ë¸ ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ---")

# 1. SARIMAX ëª¨ë¸ ì €ì¥
# - joblibì„ ì‚¬ìš©í•˜ì—¬ í†µê³„ ëª¨ë¸ ê°ì²´ë¥¼ .pkl íŒŒì¼ë¡œ ì§ë ¬í™”í•©ë‹ˆë‹¤.
joblib.dump(sarima_model, './model/sarima_final.pkl')
print("1. SARIMAX ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./model/sarima_final.pkl")

# 2. LSTM ëª¨ë¸ ì €ì¥
# - Kerasì˜ .h5(HDF5) í¬ë§·ì„ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ì™€ êµ¬ì¡°ë¥¼ í•œ ë²ˆì— ì €ì¥í•©ë‹ˆë‹¤.
lstm_model.save('./model/lstm_final.h5')
print("2. LSTM ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./model/lstm_final.h5")

# 3. ìŠ¤ì¼€ì¼ëŸ¬(Scaler) ì €ì¥ (ë§¤ìš° ì¤‘ìš”!)
# - ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•  ë•Œë„ í•™ìŠµ ë•Œì™€ ë™ì¼í•œ 'ìµœì†Œ/ìµœëŒ€' ê¸°ì¤€ì´ í•„ìš”í•©ë‹ˆë‹¤.
# - ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì €ì¥í•˜ì§€ ì•Šìœ¼ë©´ ì˜ˆì¸¡ ì‹œ ë°ì´í„° ë³€í™˜ì˜ ê¸°ì¤€ì´ ë‹¬ë¼ì ¸ ì—‰ëš±í•œ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.
joblib.dump(scaler, './model/scaler.pkl')
print("3. ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: ./model/scaler.pkl")

print("\nëª¨ë“  ëª¨ë¸ ê²°ê³¼ë¬¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ Inference ë‹¨ê³„ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

```

7. inferenceë¥¼ ìœ„í•œ ì½”ë“œ

íŒŒì¼ëª… : household6_inference.py

```python
import pandas as pd
import numpy as np
import joblib
from tensorflow.keras.models import load_model

# 1. ì €ì¥ëœ ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”©
print("ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
sarima_model = joblib.load('./model/sarima_final.pkl')
lstm_model = load_model('./model/lstm_final.h5', compile=False) 
scaler = joblib.load('./model/scaler.pkl')

# 2. ë¯¸ë˜ 7ì¼ ë°ì´í„° ì¤€ë¹„
weather_path = '.\data\paris_weather_data.csv'
df_weather = pd.read_csv(weather_path, parse_dates=['time'], index_col='time')
df_weather['temp_est'] = (df_weather['tmin'] + df_weather['tmax']) / 2
df_weather = df_weather[['temp_est', 'tmin', 'tmax', 'prcp']].interpolate().ffill().bfill()

future_X = df_weather.iloc[-7:].copy()
future_X['is_weekend'] = future_X.index.dayofweek.map(lambda x: 1 if x >= 5 else 0)

# 3. SARIMAX ì˜ˆì¸¡
sarima_forecast = sarima_model.predict(n_periods=7, X=future_X)

# 4. LSTM ì˜ˆì¸¡
# ì…ë ¥ ë°ì´í„° êµ¬ì„± (ì „ë ¥, ì˜¨ë„_í‰ê· , ìµœì €, ìµœê³ , ê°•ìˆ˜, ì£¼ë§ì—¬ë¶€) - 6ê°œ ì»¬ëŸ¼
# ì‹¤ì œ ë°ì´í„°ê°€ ì—†ëŠ” ë¯¸ë˜ ì‹œì ì´ë¯€ë¡œ, ë‚ ì”¨ ì •ë³´ë§Œ í™œìš©í•˜ì—¬ ì˜ˆì¸¡ ë£¨í”„ë¥¼ ë•ë‹ˆë‹¤.
lstm_predictions = []

# ê°€ì¥ ìµœê·¼ì˜ 7ì¼ì¹˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ êµ¬ì„± (6ê°œ ì»¬ëŸ¼ shape ë§ì¶°ì•¼ í•¨)
# ì—¬ê¸°ì„œëŠ” ì‹œì—°ì„ ìœ„í•´ 0ìœ¼ë¡œ ì±„ìš´ ë’¤ ë‚ ì”¨ë§Œ ì—…ë°ì´íŠ¸
test_input_raw = np.zeros((7, 6))
test_input_raw[:, 1:] = future_X.values
current_input_scaled = scaler.transform(test_input_raw) # (7, 6)
current_input_scaled = current_input_scaled.reshape(1, 7, 6) # (1, 7, 6)

for i in range(7):
    # ì˜ˆì¸¡ ìˆ˜í–‰
    lstm_scaled_pred = lstm_model.predict(current_input_scaled, verbose=0)
    
    # [ì—ëŸ¬ í•´ê²° í¬ì¸íŠ¸] ì˜ˆì¸¡ê°’ì—ì„œ ë‹¨ì¼ ìŠ¤ì¹¼ë¼ ê°’ ì¶”ì¶œ
    pred_val = lstm_scaled_pred.flatten()[0]
    
    # ì—­ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•´ ë”ë¯¸ ìƒì„±
    dummy_output = np.zeros((1, 6))
    dummy_output[0, 0] = pred_val # ì´ì œ ì—ëŸ¬ ì—†ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.
    inv_pred = scaler.inverse_transform(dummy_output)[0, 0]
    lstm_predictions.append(inv_pred)
    
    # ë‹¤ìŒ ë‚  ì˜ˆì¸¡ì„ ìœ„í•œ ì…ë ¥ ì—…ë°ì´íŠ¸ (ìœˆë„ìš° ì´ë™)
    new_row = np.zeros((1, 1, 6))
    new_row[0, 0, 0] = pred_val # ì˜ˆì¸¡ëœ ì „ë ¥ì„ ë‹¤ìŒ ì…ë ¥ì˜ ì „ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©
    if i < 6: # ë§ˆì§€ë§‰ ë£¨í”„ê°€ ì•„ë‹ˆë©´ ë‚ ì”¨ ì •ë³´ ì—…ë°ì´íŠ¸
        # ë‹¤ìŒ ë‚ ì˜ ìŠ¤ì¼€ì¼ë§ëœ ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¯¸ë¦¬ ìŠ¤ì¼€ì¼ë§í•´ë‘” ê°’ ì‚¬ìš©)
        next_weather_scaled = scaler.transform(test_input_raw)[i+1, 1:]
        new_row[0, 0, 1:] = next_weather_scaled
        
    current_input_scaled = np.append(current_input_scaled[:, 1:, :], new_row, axis=1)

# 5. ê²°ê³¼ ì¶œë ¥
print("\n" + "="*40)
print(f"{'ë‚ ì§œ':<12} | {'ì˜ˆì¸¡ ì‚¬ìš©ëŸ‰(kW)':<15}")
print("-" * 40)

for i in range(7):
    # SARIMA(4) + LSTM(6) ì•™ìƒë¸”
    ensemble_val = (sarima_forecast.values[i] * 0.4) + (lstm_predictions[i] * 0.6)
    target_date = future_X.index[i].strftime('%Y-%m-%d')
    weekend = " (ì£¼ë§)" if future_X['is_weekend'].iloc[i] == 1 else ""
    print(f"{target_date}{weekend:<5} | {ensemble_val:>12.2f}")

print("="*40)
```
