# ë‹¤ë³€ëŸ‰ LSTM ëª¨ë¸

ë‹¤ë³€ëŸ‰ LSTM(Multivariate Long Short-Term Memory)ì€ ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì—ì„œ **ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ ë³€ìˆ˜(ì…ë ¥ íŠ¹ì„±)ë¥¼ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ì¢…ì† ë³€ìˆ˜ë¥¼ ì˜ˆì¸¡**í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.

ì¼ë°˜ì ì¸ LSTMì´ í•˜ë‚˜ì˜ ë³€ìˆ˜(ì˜ˆ: ê³¼ê±° ì£¼ê°€)ë§Œìœ¼ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•œë‹¤ë©´, ë‹¤ë³€ëŸ‰ LSTMì€ ì—¬ëŸ¬ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ë³€ìˆ˜ë“¤ì„ ì—®ì–´ ë³µí•©ì ì¸ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.

---

## 1. ë‹¤ë³€ëŸ‰ LSTM ëª¨ë¸ ì„¤ê³„

### 1. ë‹¤ë³€ëŸ‰ LSTMì˜ ê°œë…

LSTMì€ ê¸°ë³¸ì ìœ¼ë¡œ RNN(ìˆœí™˜ ì‹ ê²½ë§)ì˜ 'ì¥ê¸° ì˜ì¡´ì„± ì‚­ì œ' ë¬¸ì œë¥¼ í•´ê²°í•œ ëª¨ë¸ì…ë‹ˆë‹¤. **ë‹¤ë³€ëŸ‰(Multivariate)** ëª¨ë¸ì€ LSTMì´ ê°–ëŠ” ê¸°ìˆ ì  íŠ¹ì§•ê³¼ ë°ì´í„° ì²˜ë¦¬ ë°©ì‹ì— **ì°¨ì›(Dimension)** ì˜ ê°œë…ì„ ë”í•œ ê²ƒì…ë‹ˆë‹¤.

* **ì…ë ¥($X$):**  ì‹œì ì—ì„œì˜ ì…ë ¥ì´ ë‹¨ì¼ ê°’ì´ ì•„ë‹Œ ë²¡í„°($x_1, x_2, ..., x_n$) í˜•íƒœì…ë‹ˆë‹¤.
* **íŠ¹ì§•:** ë³€ìˆ˜ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸°ì˜¨ë¿ë§Œ ì•„ë‹ˆë¼ ìŠµë„ì™€ í’ì†ì´ ì–´ë–»ê²Œ ì„œë¡œ ì˜í–¥ì„ ì£¼ì–´ ê°•ìˆ˜ëŸ‰ì„ ê²°ì •í•˜ëŠ”ì§€ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.

---

### 2. ëª¨ë¸ êµ¬ì¡°

ë‹¤ë³€ëŸ‰ LSTMì˜ í•µì‹¬ êµ¬ì¡°ëŠ” ê° ì‹œì ($t$)ì—ì„œ ì—¬ëŸ¬ í”¼ì²˜ê°€ ë“¤ì–´ì™€ë„ ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ **Gate(ê²Œì´íŠ¸)** ì‹œìŠ¤í…œì— ìˆìŠµë‹ˆë‹¤.

#### ë‚´ë¶€ ë©”ì»¤ë‹ˆì¦˜

1. **ì…ë ¥ ë‹¨ê³„:** ì—¬ëŸ¬ ê°œì˜ ì‹œê³„ì—´ ë³€ìˆ˜ê°€ ë³‘ë ¬ë¡œ ì…ë ¥ë©ë‹ˆë‹¤. ë°ì´í„°ì˜ í˜•íƒœëŠ” ë³´í†µ `[Samples, Time Steps, Features]`ì…ë‹ˆë‹¤.
2. **Forget Gate (ë§ê° ê²Œì´íŠ¸):** ê³¼ê±° ì •ë³´ ì¤‘ ì–´ë–¤ ê²ƒì„ ë²„ë¦´ì§€ ê²°ì •í•©ë‹ˆë‹¤.
3. **Input Gate (ì…ë ¥ ê²Œì´íŠ¸):** í˜„ì¬ ì‹œì ì˜ ë‹¤ë³€ëŸ‰ ë°ì´í„° ì¤‘ ì–´ë–¤ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì…€ ìƒíƒœì— ì €ì¥í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.
4. **Cell State (ì…€ ìƒíƒœ):** í•µì‹¬ ì •ë³´ê°€ ê´€í†µí•˜ëŠ” í†µë¡œë¡œ, ë‹¤ë³€ëŸ‰ ê°„ì˜ ë³µì¡í•œ ê´€ê³„ë¥¼ ì¥ê¸°ì ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
5. **Output Gate (ì¶œë ¥ ê²Œì´íŠ¸):** ê°€ê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

---

### 3. ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€? (í™œìš© ì˜ˆì‹œ)

ë‹¨ì¼ ë³€ìˆ˜ë§Œìœ¼ë¡œëŠ” ì„¤ëª…ì´ ë¶€ì¡±í•œ **ë³µí•©ì ì¸ ì‹œìŠ¤í…œ**ì„ ì˜ˆì¸¡í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

#### â‘  ì£¼ì‹ ë° ê¸ˆìœµ ì‹œì¥ ì˜ˆì¸¡

* **ì…ë ¥ ë³€ìˆ˜:** ê³¼ê±° ì£¼ê°€, ê±°ë˜ëŸ‰, ê¸ˆë¦¬, í™˜ìœ¨, ì›ìì¬ ê°€ê²©
* **ì´ìœ :** ì£¼ê°€ëŠ” ë‹¨ìˆœíˆ ê³¼ê±° ì£¼ê°€ë¿ë§Œ ì•„ë‹ˆë¼ ê±°ì‹œ ê²½ì œ ì§€í‘œì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

#### â‘¡ ê¸°ìƒ ë° ë¯¸ì„¸ë¨¼ì§€ ì˜ˆì¸¡

* **ì…ë ¥ ë³€ìˆ˜:** ì˜¨ë„, ìŠµë„, ëŒ€ê¸°ì••, í’í–¥, ì¸ê·¼ ì§€ì—­ì˜ ì˜¤ì—¼ ë†ë„
* **ì´ìœ :** ë¯¸ì„¸ë¨¼ì§€ ë†ë„ëŠ” ë°”ëŒì˜ ë°©í–¥ì´ë‚˜ ìŠµë„ ë“± ë‹¤ì–‘í•œ ê¸°ìƒ ìš”ì¸ê³¼ ë³µí•©ì ìœ¼ë¡œ ì–½í˜€ ìˆìŠµë‹ˆë‹¤.

#### â‘¢ ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì„¤ë¹„ ì´ìƒ íƒì§€

* **ì…ë ¥ ë³€ìˆ˜:** ì§„ë™, ì†ŒìŒ, ì „ë¥˜, ì „ì••, ì˜¨ë„
* **ì´ìœ :** íŠ¹ì • ë¶€í’ˆì˜ ê³ ì¥ì€ í•˜ë‚˜ì˜ ì§€í‘œê°€ ì•„ë‹Œ ì—¬ëŸ¬ ì„¼ì„œì˜ ë¯¸ì„¸í•œ ë™ì‹œ ë³€í™”ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

---

### 4. ë‹¤ë³€ëŸ‰ LSTM êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­

* **ë°ì´í„° ìŠ¤ì¼€ì¼ë§:** ë³€ìˆ˜ë§ˆë‹¤ ë‹¨ìœ„(ì˜ˆ: ì˜¨ë„ëŠ” 20ë„, ì „ì••ì€ 220V)ê°€ ë‹¤ë¥´ë¯€ë¡œ **Min-Max Scaling**ì´ë‚˜ **Standardization**ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.
* **ì‹œì°¨(Lag) ì„¤ì •:** ì–´ë–¤ ë³€ìˆ˜ê°€ ì˜ˆì¸¡ ëŒ€ìƒì— ì˜í–¥ì„ ì£¼ê¸°ê¹Œì§€ ê±¸ë¦¬ëŠ” ì‹œê°„(Time Lag)ì„ ê³ ë ¤í•˜ì—¬ ìœˆë„ìš° ì‚¬ì´ì¦ˆë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
* **ê³¼ì í•©(Overfitting):** ë³€ìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ëª¨ë¸ì´ ë³µì¡í•´ì ¸ í•™ìŠµ ë°ì´í„°ì—ë§Œ ê³¼í•˜ê²Œ ìµœì í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Dropoutì´ë‚˜ ê·œì œ ê¸°ë²•ì„ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

---

## 2. ë‹¤ë³€ëŸ‰ LSTM ëª¨ë¸ êµ¬í˜„ (day4/step1 í´ë” ì°¸ì¡°)

ìŠ¤ë§ˆíŠ¸ ê¸°ê¸° ì „ë ¥ ì‚¬ìš©ëŸ‰ ë°ì´í„°ë¥¼ í™œìš©í•œ ë‹¤ë³€ëŸ‰ LSTM ëª¨ë¸ êµ¬ì¶•ì„ ìœ„í•´, **[ë¶„ì„ ë° ì„¤ê³„ ì ˆì°¨]** ì™€ ì‹¤ì œ ì‹¤í–‰í•´ì•¼ í•  **[ì‘ì—… ë‹¨ê³„]** ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

---

### 1. ë‹¤ë³€ëŸ‰ LSTM êµ¬ì¶• ë¡œë“œë§µ (ì„¤ê³„ + ì‹¤í–‰)

ì „ì²´ ê³¼ì •ì€ **ë°ì´í„° ì´í•´ â†’ ê°€ê³µ â†’ ë³€í™˜ â†’ í•™ìŠµ â†’ ê²€ì¦**ì˜ íë¦„ì„ ë”°ë¦…ë‹ˆë‹¤.

#### **1ë‹¨ê³„: ë°ì´í„° íƒìƒ‰ ë° ìš”êµ¬ì‚¬í•­ ì •ì˜ (EDA(Exploratory Data Analysis))**

* **ì„¤ê³„ ì „ëµ:** ë°ì´í„°ì˜ íŠ¹ì„±ì„ íŒŒì•…í•˜ì—¬ ì˜ˆì¸¡ì— ë°©í•´ê°€ ë˜ëŠ” ìš”ì†Œë¥¼ ì œê±°í•©ë‹ˆë‹¤.
* **ì‹¤í–‰ ë‚´ìš©:**
  * `Date`, `Temperature`, `Usage` í•„ë“œì˜ ê²°ì¸¡ì¹˜(NaN) í™•ì¸.
  * ì‹œê°„ì— ë”°ë¥¸ ì‚¬ìš©ëŸ‰ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ë©° **ì£¼ê¸°ì„±(Daily/Weekly)** ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
  * ìŠ¤ë§ˆíŠ¸ ê¸°ê¸° íŠ¹ì„±ìƒ ì‚¬ìš©ëŸ‰ì´ 0ì¸ êµ¬ê°„(êº¼ì§)ì´ë‚˜ ê°‘ì‘ìŠ¤ëŸ¬ìš´ í”¼í¬(ì—ì–´ì»¨ ê°€ë™ ë“±)ë¥¼ ì²´í¬í•©ë‹ˆë‹¤.

> ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì˜ˆì œ : day3/step4/clean_data.py ì°¸ì¡°í•˜ì„¸ìš”

#### **2ë‹¨ê³„: íŠ¹ì„± ê³µí•™ (Feature Engineering)**

* **ì„¤ê³„ ì „ëµ:** ëª¨ë¸ì´ "ì‹œê°„ì˜ íë¦„"ê³¼ "ê¸°ì˜¨ì˜ ì˜í–¥"ì„ ë™ì‹œì— ì´í•´í•˜ë„ë¡ íŠ¹ì„±ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.
* **ì‹¤í–‰ ë‚´ìš©:**
  * **Cyclical Encoding:** ì‹œê°„ ë°ì´í„°(0~23)ë¥¼ $sin$ê³¼ $cos$ê°’ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ëŠ” 23ì‹œì™€ 0ì‹œê°€ ìˆ˜ì¹˜ì ìœ¼ë¡œ ë©€ì§€ë§Œ ì‹œê°„ìƒìœ¼ë¡œëŠ” ì¸ì ‘í•¨ì„ ëª¨ë¸ì— ì•Œë ¤ì£¼ëŠ” **íŠ¹ë³„í•œ ì²˜ë¦¬**ì…ë‹ˆë‹¤.
  * **ë‹¤ë³€ëŸ‰ ê²°í•©:** ì˜¨ë„ì™€ ì „ë ¥ëŸ‰, ê·¸ë¦¬ê³  ì¸ì½”ë”©ëœ ì‹œê°„ ë³€ìˆ˜ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„° í…Œì´ë¸”ë¡œ ê²°í•©í•©ë‹ˆë‹¤.

#### **3ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ (Preprocessing)**

* **ì„¤ê³„ ì „ëµ:** ì‹ ê²½ë§ í•™ìŠµì— ìµœì í™”ëœ ìˆ˜ì¹˜ ë²”ìœ„ì™€ 3ì°¨ì› ì…ë ¥ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
* **ì‹¤í–‰ ë‚´ìš©:**
  * **Scaling:** `MinMaxScaler`ë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ë¡œ ë§ì¶¥ë‹ˆë‹¤.
  * **Sliding Window:** ê³¼ê±° 24ì‹œê°„($t-24 \sim t-1$)ì„ ë³´ê³  í˜„ì¬($t$)ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ 3ì°¨ì› ë°°ì—´(`[samples, time_steps, features]`)ì„ ìƒì„±í•©ë‹ˆë‹¤.

#### **4ë‹¨ê³„: ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ (Modeling)**

* **ì„¤ê³„ ì „ëµ:** ë‹¤ë³€ëŸ‰ LSTM ì¸µì„ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ë¹„ì„ í˜• íŒ¨í„´ ì¶”ì¶œì„ ì§„í–‰í•©ë‹ˆë‹¤.
* **ì‹¤í–‰ ë‚´ìš©:**
  * **Input Layer:** 24ì‹œê°„ì˜ íƒ€ì„ìŠ¤í…ê³¼ 4ê°œì˜ í”¼ì²˜ë¥¼ ë°›ëŠ” ì…ë ¥ì¸µ.
  * **LSTM Layer:** 50~64ê°œì˜ ìœ ë‹›ì„ ê°€ì§„ ë‹¨ì¼ ì¸µ êµ¬ì„±.
  * **Dropout:** í•™ìŠµ ë°ì´í„°ì—ë§Œ ê³¼í•˜ê²Œ ìµìˆ™í•´ì§€ëŠ” ê³¼ì í•©(Overfitting)ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ 20%ì˜ ë…¸ë“œë¥¼ ë¬´ì‘ìœ„ë¡œ ì œì™¸í•©ë‹ˆë‹¤.
  * **Dense Layer:** ìµœì¢…ì ìœ¼ë¡œ 1ê°œì˜ ì „ë ¥ ì‚¬ìš©ëŸ‰ ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

#### **5ë‹¨ê³„: í‰ê°€ ë° ì˜ˆì¸¡ (Evaluation)**

* **ì„¤ê³„ ì „ëµ:** ë³´ì§€ ëª»í•œ ë°ì´í„°(Test Set)ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì‹¤ì „ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
* **ì‹¤í–‰ ë‚´ìš©:**
  * í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³ , ì‹¤ì œ ì‚¬ìš©ëŸ‰ ê·¸ë˜í”„ì™€ ê²¹ì³ì„œ ë¹„êµí•©ë‹ˆë‹¤.
  * MSE(Mean Squared Error) ë“±ì˜ ì§€í‘œë¡œ ì˜¤ì°¨ë¥¼ ìˆ˜ì¹˜í™”í•©ë‹ˆë‹¤.

---

íŒŒì¼ëª… : day4/step1/main.py

### ìµœì¢… í†µí•© ì½”ë“œ (Python)

ìœ„ì˜ ëª¨ë“  ì ˆì°¨ë¥¼ êµ¬í˜„í•œ ì½”ë“œì…ë‹ˆë‹¤.

```python
import pandas as pd
import numpy as np
import koreanize_matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# 1. ì‹œê°í™” ë° í™˜ê²½ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False 

# [ë‹¨ê³„ 1] ë°ì´í„° ë¡œë“œ ë° ì‹œê°„ ë³€í™˜
df = pd.read_csv('./data/power_usage_dataset.csv')
df['Date'] = pd.to_datetime(df['Date'])

# [ë‹¨ê³„ 2] íŠ¹ì„± ê³µí•™ (Cycle Encoding)
# 23ì‹œì™€ 0ì‹œê°€ ì—°ì†ì ì„ì„ ëª¨ë¸ì—ê²Œ ì•Œë ¤ì£¼ëŠ” ì¤‘ìš”í•œ ê³¼ì •ì…ë‹ˆë‹¤.
df['hour'] = df['Date'].dt.hour
df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 23)
df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 23)

features_list = ['Temperature', 'Usage', 'hour_sin', 'hour_cos']
data = df[features_list].values

# [ë‹¨ê³„ 3] ë°ì´í„° ì „ì²˜ë¦¬ (ìŠ¤ì¼€ì¼ë§ ë° ì‹œí€€ìŠ¤ ìƒì„±)
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

def create_sequences(data, window_size=24):
    X, y = [], []
    for i in range(len(data) - window_size):
        X.append(data[i:i + window_size, :]) 
        y.append(data[i + window_size, 1]) # Target: Usage
    return np.array(X), np.array(y)

window_size = 24 # 1ì£¼ì¼(24ì‹œê°„) íŒ¨í„´ í•™ìŠµ
X, y = create_sequences(scaled_data, window_size)

# ë°ì´í„° ë¶„í• 
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

print(f"âœ… í•™ìŠµ ë°ì´í„° ê·œê²©: {X_train.shape} (ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í…, í”¼ì²˜ ìˆ˜)")

# [ë‹¨ê³„ 4] ëª¨ë¸ ì„¤ê³„ (ìµœì‹  ê¶Œì¥ ìŠ¤íƒ€ì¼: Input ë ˆì´ì–´ ë° Stacked êµ¬ì¡°)
model = Sequential([
    Input(shape=(window_size, 4)), # ì…ë ¥ ê·œê²© ëª…ì‹œ
#    Input(shape=(X_train.shape[1], X_train.shape[2])), # X_train ë³€ìˆ˜ë¥¼ í™œìš©í•œ ê·œê²© ëª…ì‹œ (24, 4)ë¡œ ë³€ê²½
    LSTM(units=128, activation='tanh'),
    Dense(32, activation='tanh'),
    Dense(units=1)
])

# [ë‹¨ê³„ 5] ì»´íŒŒì¼ ë° ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
model.compile(optimizer='adam', loss='mse')

early_stop = EarlyStopping(
    monitor='val_loss',         # ê°ì‹œ ëŒ€ìƒ: ê²€ì¦ ë°ì´í„°ì˜ ì†ì‹¤ ê°’
    patience=7,                 # ì„±ëŠ¥ ê°œì„ ì´ ì—†ì„ ë•Œ ê¸°ë‹¤ë ¤ì¤„ ì—í¬í¬ íšŸìˆ˜
    restore_best_weights=True   # í•™ìŠµ ì¢…ë£Œ í›„ ê°€ì¥ ì„±ì ì´ ì¢‹ì•˜ë˜ ì‹œì ì˜ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
)

# ëª¨ë¸ í•™ìŠµ
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.1,
    callbacks=[early_stop], #ì¡°ê¸° ì¢…ë£Œ ì½œë°± ì¶”ê°€
    verbose=1
)

# [ë‹¨ê³„ 6] ì˜ˆì¸¡ ë° ì—­ìŠ¤ì¼€ì¼ë§
predictions_scaled = model.predict(X_test)

def get_original_units(scaled_values, scaler, feature_count, target_idx=1):
    dummy = np.zeros((len(scaled_values), feature_count))
    dummy[:, target_idx] = scaled_values.flatten()
    return scaler.inverse_transform(dummy)[:, target_idx]

y_test_original = get_original_units(y_test, scaler, len(features_list))
predictions_original = get_original_units(predictions_scaled, scaler, len(features_list))

# [ë‹¨ê³„ 7] ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(14, 6))
plt.plot(y_test_original[:168], label='ì‹¤ì œê°’', color='#1f77b4', alpha=0.8, linewidth=2)
plt.plot(predictions_original[:168], label='ì˜ˆì¸¡ê°’', color='#ff7f0e', linestyle='--', linewidth=2)
plt.title('ë‹¤ë³€ëŸ‰ LSTM: ì „ë ¥ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡')
plt.xlabel('ì‹œê°„')
plt.ylabel('ì „ë ¥ ì‚¬ìš©ëŸ‰(kW)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

```

---

### ì‹¤í–‰ ê²°ê³¼

![alt text](image.png)

---

### í•µì‹¬ í¬ì¸íŠ¸

* **ì„¤ê³„ì˜ í•µì‹¬:** ë‹¨ìˆœíˆ ìˆ«ìë¥¼ ë„£ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, `sin/cos` ë³€í™˜ê³¼ ê°™ì€ **ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ì˜ íŠ¹ì„± ì¶”ì¶œ** ì´ ëª¨ë¸ì˜ ì§€ëŠ¥ì„ ê²°ì •í•©ë‹ˆë‹¤.
* **êµ¬ì¡°ì˜ ë‹¨ìˆœí™”:** ë‹¤ë³€ëŸ‰ LSTMì„ ì‚¬ìš©í•˜ì—¬ ì—°ì‚° ë¶€í•˜ë¥¼ ì¤„ì´ê³  ê³¼ì í•©ì„ ë°©ì§€í–ˆìŠµë‹ˆë‹¤.
* **ë°ì´í„°ì˜ ì—°ê²°:** `create_sequences` í•¨ìˆ˜ê°€ ë°”ë¡œ ì„¤ê³„ ì „ëµ(ê³¼ê±°ë¥¼ í†µí•´ ë¯¸ë˜ë¥¼ ë³¸ë‹¤)ì„ ë¬¼ë¦¬ì ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” í•µì‹¬ ì¥ì¹˜ì…ë‹ˆë‹¤.

---

## 3. ë‹¤ë³€ëŸ‰ LSTM ëª¨ë¸ êµ¬í˜„ ì‹œ íŠ¹ì„± ì¶”ê°€ (day4/step1 í´ë” ì°¸ì¡° main2.py)

í‰ì¼ê³¼ ì£¼ë§ì€ ìŠ¤ë§ˆíŠ¸ ê¸°ê¸° ì‚¬ìš© íŒ¨í„´(ì˜ˆ: ê°€ì „ì œí’ˆ ê°€ë™ ì‹œê°„, ì¬íƒ ì—¬ë¶€ ë“±)ì— ê²°ì •ì ì¸ ì°¨ì´ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ë¥¼ ëª¨ë¸ì— ì•Œë ¤ì£¼ê¸° ìœ„í•´ **ì£¼ë§ ì—¬ë¶€ë¥¼ 0(í‰ì¼)ê³¼ 1(ì£¼ë§)** ë¡œ í‘œì‹œí•˜ëŠ” ë°”ì´ë„ˆë¦¬ íŠ¹ì„±ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ ë³´ê² ìŠµë‹ˆë‹¤.

---

### 1. íŠ¹ì„± ê³µí•™ (Feature Engineering) ì¶”ê°€

* **Is_Weekend í”¼ì²˜ ìƒì„±:** `Date` í•„ë“œì—ì„œ ìš”ì¼ì„ ì¶”ì¶œí•˜ì—¬ í† ìš”ì¼(5)ê³¼ ì¼ìš”ì¼(6)ì¸ ê²½ìš°ë¥¼ 1ë¡œ, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
* **ë‹¤ë³€ëŸ‰ ê²°í•©:** ì´ì œ ëª¨ë¸ì€ [ì˜¨ë„, ì „ë ¥ëŸ‰, ì‹œê°„_sin, ì‹œê°„_cos, **ì£¼ë§ì—¬ë¶€**] ì´ 5ê°œì˜ ë³€ìˆ˜ë¥¼ ë™ì‹œì— í•™ìŠµí•©ë‹ˆë‹¤.

### 2. ë°ì´í„° ì „ì²˜ë¦¬

* **ìŠ¤ì¼€ì¼ë§:** ì£¼ë§ ì—¬ë¶€(0 ë˜ëŠ” 1)ë„ ìŠ¤ì¼€ì¼ëŸ¬ì— í¬í•¨ì‹œì¼œ ëª¨ë¸ì´ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ê³¼ ë™ì¼í•œ ì„ ìƒì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•©ë‹ˆë‹¤.
* **ìœˆë„ìš° êµ¬ì¡°:** ì…ë ¥ í”¼ì²˜ê°€ 4ê°œì—ì„œ **5ê°œ**ë¡œ ëŠ˜ì–´ë‚¨ì— ë”°ë¼ `input_shape`ê°€ ìë™ìœ¼ë¡œ ì¡°ì •ë©ë‹ˆë‹¤.

---

íŒŒì¼ëª… : day4/step1/main2.py

## ğŸ’» ìµœì¢… í†µí•© ì½”ë“œ (í‰ì¼/ì£¼ë§ êµ¬ë¶„ í¬í•¨)

```python
import pandas as pd
import numpy as np
import koreanize_matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# 1. í™˜ê²½ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False 

# [ë‹¨ê³„ 1] ë°ì´í„° ë¡œë“œ
df = pd.read_csv('./data/power_usage_dataset.csv')
df['Date'] = pd.to_datetime(df['Date'])

# [ë‹¨ê³„ 2] íŠ¹ì„± ê³µí•™ (Feature Engineering)
# (1) ì‹œê°„ ì£¼ê¸°ì„± ë³€í™˜
df['hour'] = df['Date'].dt.hour
df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 23)
df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 23)

# (2) ì£¼ë§ ë³€ìˆ˜ ì¶”ê°€ (í† /ì¼ì€ 1, í‰ì¼ì€ 0)
df['is_weekend'] = df['Date'].dt.weekday.map(lambda x: 1 if x >= 5 else 0)

# ì‚¬ìš©í•  íŠ¹ì„± ë¦¬ìŠ¤íŠ¸ (ì´ 5ê°œ)
features_list = ['Temperature', 'Usage', 'hour_sin', 'hour_cos', 'is_weekend']
data = df[features_list].values

# [ë‹¨ê³„ 3] ë°ì´í„° ì „ì²˜ë¦¬
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

def create_sequences(data, window_size=24):
    X, y = [], []
    for i in range(len(data) - window_size):
        X.append(data[i:i + window_size, :]) 
        y.append(data[i + window_size, 1]) # Target: Usage
    return np.array(X), np.array(y)

window_size = 24 # ê³¼ê±° 24ì‹œê°„ íŒ¨í„´ í•™ìŠµ
X, y = create_sequences(scaled_data, window_size)

# ë°ì´í„° ë¶„í•  (ìˆœì„œ ìœ ì§€)
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# [ë‹¨ê³„ 4] ìµœì‹  ìŠ¤íƒ€ì¼ ëª¨ë¸ ì„¤ê³„ (Stacked LSTM)
model = Sequential([
    Input(shape=(X_train.shape[1], X_train.shape[2])), # (24, 5) ê·œê²© ëª…ì‹œ
    LSTM(128, activation='tanh'),
    Dense(32, activation='tanh'),
    Dense(1)
])

# [ë‹¨ê³„ 5] ì»´íŒŒì¼ 
model.compile(optimizer='adam', loss='mse')

# ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
early_stop = EarlyStopping(
    monitor='val_loss', 
    patience=7, 
    restore_best_weights=True
)

# ëª¨ë¸ í•™ìŠµ
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.1,
    callbacks=[early_stop],
    verbose=1
)

# [ë‹¨ê³„ 6] ì˜ˆì¸¡ ë° ì—­ìŠ¤ì¼€ì¼ë§
predictions_scaled = model.predict(X_test)

def get_original_units(scaled_values, scaler, feature_count, target_idx=1):
    """5ê°œ ë³€ìˆ˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©° Target(ì „ë ¥ëŸ‰)ë§Œ ì—­ë³€í™˜"""
    dummy = np.zeros((len(scaled_values), feature_count))
    dummy[:, target_idx] = scaled_values.flatten()
    return scaler.inverse_transform(dummy)[:, target_idx]

y_test_original = get_original_units(y_test, scaler, len(features_list))
predictions_original = get_original_units(predictions_scaled, scaler, len(features_list))

# [ë‹¨ê³„ 7] ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(14, 6))
plt.plot(y_test_original[:168], label='ì‹¤ì œê°’', color='#1f77b4', linewidth=2)
plt.plot(predictions_original[:168], label='ì˜ˆì¸¡ê°’', color='#ff7f0e', linestyle='--', linewidth=2)
plt.title('ë‹¤ë³€ëŸ‰ LSTM (Weekend Feature): ìŠ¤ë§ˆíŠ¸ ê¸°ê¸° ì „ë ¥ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡')
plt.xlabel('ì‹œê°„ (1ì£¼ì¼ì¹˜)')
plt.ylabel('ì „ë ¥ ì‚¬ìš©ëŸ‰(kW)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

```

---

### ì‹¤í–‰ ê²°ê³¼ (ê²°ê³¼ ì´ë¯¸ì§€ ë¹„êµ)

![alt text](image-1.png)

---

![alt text](image.png)

## 4. ë¶„ì„ í›„ ì¶”ê°€ ì‘ì—… (day4/step1 í´ë” ì°¸ì¡° main3.py)

í‰ì¼/ì£¼ë§ í”¼ì²˜ë¥¼ ì¶”ê°€í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê²°ê³¼ê°€ ì˜¤íˆë ¤ ì•ˆ ì¢‹ê²Œ ë‚˜ì˜¤ëŠ” í˜„ìƒì€ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ë§ì—ì„œ í”íˆ ë°œìƒí•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.

---

### 1. ì™œ ì£¼ë§ í”¼ì²˜ë¥¼ ë„£ì—ˆëŠ”ë° ê²°ê³¼ê°€ ë” ì•ˆ ì¢‹ì„ê¹Œ?

#### **ì›ì¸ 1: ë°ì´í„°ì˜ ë¶€ì¡± (Data Scarcity)**

LSTMì€ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ì „ì²´ ë°ì´í„° ì¤‘ í‰ì¼ì€ 5/7(ì•½ 71%)ì„ ì°¨ì§€í•˜ì§€ë§Œ, ì£¼ë§ì€ 2/7(ì•½ 28%)ë¿ì…ë‹ˆë‹¤. ëª¨ë¸ ì…ì¥ì—ì„œëŠ” ì£¼ë§ íŒ¨í„´ì„ ì¶©ë¶„íˆ í•™ìŠµí•  ë°ì´í„° ì–‘ì´ ë¶€ì¡±í•œ ìƒíƒœì—ì„œ ìƒˆë¡œìš´ ë³€ìˆ˜ê°€ ë“¤ì–´ì˜¤ë‹ˆ ì˜¤íˆë ¤ **ë…¸ì´ì¦ˆ** ë¡œ ë°›ì•„ë“¤ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### **ì›ì¸ 2: "ì£¼ë§"ì´ë¼ëŠ” ì‹ í˜¸ì˜ ë‹¨ìˆœí•¨ (Binary Featureì˜ í•œê³„)**

ë‹¨ìˆœíˆ 0ê³¼ 1ë¡œë§Œ êµ¬ë¶„í•˜ë©´ ëª¨ë¸ì€ "ì£¼ë§ì—” ë¬´ì¡°ê±´ ë†’ë‹¤/ë‚®ë‹¤" ì‹ì˜ ë‹¨ìˆœí•œ ì˜¤í”„ì…‹(Offset)ë§Œ í•™ìŠµí•˜ë ¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì£¼ë§ ì•ˆì—ì„œë„ í† ìš”ì¼ê³¼ ì¼ìš”ì¼ì˜ íŒ¨í„´ì´ ë‹¤ë¥¼ ìˆ˜ ìˆê³ , ê¸°ì˜¨ê³¼ì˜ ìƒí˜¸ì‘ìš©ì´ í‰ì¼ê³¼ ë‹¤ë¥´ê²Œ ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### **ì›ì¸ 3: í”¼ì²˜ ê°„ì˜ ë¶ˆê· í˜• (Feature Scaling)**

`is_weekend`ëŠ” 0ê³¼ 1ë¡œ ëª…í™•íˆ ë‚˜ë‰˜ëŠ” ë°˜ë©´, ì˜¨ë„ë‚˜ ì‚¬ìš©ëŸ‰ì€ ì—°ì†ì ì¸ ê°’ì…ë‹ˆë‹¤. ëª¨ë¸ì´ í•™ìŠµ ê³¼ì •ì—ì„œ ì´ ê°‘ì‘ìŠ¤ëŸ¬ìš´ 0/1 ì‹ í˜¸ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í• ì§€ í˜¼ë€ì„ ê²ªìœ¼ë©° ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ëŠ” ë° ë°©í•´ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### 2. ë‘ ë²ˆì§¸ ê²°ê³¼(ì£¼ë§ í¬í•¨)ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•

ê²°ê³¼ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆëŠ” **íŠ¹ë³„í•œ ì²˜ë¦¬** ì „ëµë“¤ì…ë‹ˆë‹¤.

#### **ë°©ë²• 1: ìœˆë„ìš° í¬ê¸°(Window Size) í™•ì¥**

í˜„ì¬ 24ì‹œê°„(í•˜ë£¨) íŒ¨í„´ë§Œ ë³´ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì£¼ë§ íŒ¨í„´ì„ ì´í•´í•˜ë ¤ë©´ **ìµœì†Œ ì¼ì£¼ì¼(168ì‹œê°„)** ì •ë„ì˜ íë¦„ì„ ëª¨ë¸ì´ í•œ ë²ˆì— ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

* **ìˆ˜ì • ì‚¬í•­:** `window_size = 24` â†’ `window_size = 168` (ë°ì´í„° ì–‘ì´ ì¶©ë¶„í•  ê²½ìš°)

#### **ë°©ë²• 2: ìš”ì¼ë³„ ì„ë² ë”© ë˜ëŠ” ì„¸ë¶„í™”**

0/1ì´ ì•„ë‹ˆë¼ 0(ì›”) ~ 6(ì¼)ê¹Œì§€ì˜ ìš”ì¼ ì •ë³´ë¥¼ ë„£ê³ , ì´ë¥¼ ë‹¤ì‹œ Sin/Cosìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìš”ì¼ ê°„ì˜ ì—°ì†ì„±ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

* **íš¨ê³¼:** ê¸ˆìš”ì¼ ë°¤ê³¼ í† ìš”ì¼ ì•„ì¹¨ì˜ ì—°ê²°ì„±ì„ ëª¨ë¸ì´ ë” ì˜ ì´í•´í•˜ê²Œ ë©ë‹ˆë‹¤.

#### **ë°©ë²• 3: ê°€ì¤‘ì¹˜ ë¶€ì—¬ (Sample Weighting)**

ë°ì´í„° ìˆ˜ê°€ ì ì€ ì£¼ë§ ë°ì´í„°ì— ëŒ€í•´ **Loss(ì†ì‹¤ í•¨ìˆ˜) ê°€ì¤‘ì¹˜**ë¥¼ ë” ë†’ê²Œ ì„¤ì •í•˜ì—¬, ëª¨ë¸ì´ ì£¼ë§ ë°ì´í„°ë¥¼ í‹€ë ¸ì„ ë•Œ ë” í° ë²Œì¹™ì„ ë°›ê²Œ í•©ë‹ˆë‹¤.

#### **ë°©ë²• 4: ìƒí˜¸ì‘ìš© í”¼ì²˜(Interaction Feature) ìƒì„±**

ì˜¨ë„ê°€ ì‚¬ìš©ëŸ‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í‰ì¼ê³¼ ì£¼ë§ì— ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* **ì˜ˆ:** `Temp_Weekend = Temperature * is_weekend` ë¼ëŠ” í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ì—¬ ì£¼ë§ íŠ¹í™” ì˜¨ë„ ë°˜ì‘ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

---

### 3. ê°œì„ ëœ ì½”ë“œ (ìš”ì¼ ì£¼ê¸°ì„± ì¶”ê°€)

ë‹¨ìˆœ 0/1 ë³´ë‹¤ëŠ” **ìš”ì¼ ì£¼ê¸°ì„±**ì„ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ë” ì¢‹ìŠµë‹ˆë‹¤.

ì•„ë˜ ì˜ˆì œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ëŠ” **3ê°œì›” ì¸¡ì • ë°ì´í„°** ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.

íŒŒì¼ëª… : day4/step1/main3.py

```python
# ê¸°ì¡´ is_weekend ëŒ€ì‹  ìš”ì¼ ì£¼ê¸°ì„±(Sin/Cos) ì ìš© ì˜ˆì‹œ
df['weekday'] = df['Date'].dt.weekday
df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 6)
df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 6)

# í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
features_list = ['Temperature', 'Usage', 'hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos']

```

---

### ì‹¤í–‰ ê²°ê³¼

![alt text](image-2.png)
