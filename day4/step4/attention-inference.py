import numpy as np
import pandas as pd
import koreanize_matplotlib
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import  Layer, Input, LSTM, Dense
import joblib
import os

# 1. Attention ë ˆì´ì–´ í´ë˜ìŠ¤ ì •ì˜ (ë¡œë“œ ì‹œ í•„ìˆ˜)
# @tf.keras.utils.register_keras_serializable()ëŠ” í•™ìŠµ ì‹œ ë“±ë¡ëœ ì´ë¦„ì„ ì°¾ê¸° ìœ„í•´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
@tf.keras.utils.register_keras_serializable(package="Custom")
class AttentionLayer(Layer):
    """
    LSTMì˜ ì¶œë ¥ ì‹œí€€ìŠ¤ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘(Attention)í•˜ì—¬ 
    ê°€ì¤‘ í•©ì‚°ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ìƒì„±í•˜ëŠ” ì»¤ìŠ¤í…€ ë ˆì´ì–´ì…ë‹ˆë‹¤.
    """
    def __init__(self, **kwargs):
        # ë¶€ëª¨ í´ë˜ìŠ¤(layers.Layer)ì˜ ì´ˆê¸°í™” ë£¨í‹´ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        """
        ë ˆì´ì–´ê°€ ì²˜ìŒ í˜¸ì¶œë  ë•Œ ì‹¤í–‰ë˜ë©°, í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜(Weight)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        input_shape:     (Batch_size, Time_steps, Input_dim) í˜•íƒœì…ë‹ˆë‹¤.
        ë°°ì—´ì„ ì™¼ìª½ì— ì ‘ê·¼   :  0           1           2
        ë°°ì—´ì„ ì™¼ë¥¸ìª½ì— ì ‘ê·¼ : -3          -2          -1
        """
        # 1. í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ W ì •ì˜: ê° ì‹œì ì˜ íŠ¹ì§•ê°’ì— ê³±í•´ì§ˆ ê°€ì¤‘ì¹˜ í–‰ë ¬
        # í˜•íƒœ: (ì…ë ¥ ì°¨ì›, 1) -> ê° ì‹œì ì˜ ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ ì ìˆ˜ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•¨
        self.W = self.add_weight(name="att_weight", 
                                 shape=(input_shape[-1], 1), 
                                 initializer="normal",
                                 trainable=True)
        
        # 2. í¸í–¥ b ì •ì˜: í™œì„±í™” í•¨ìˆ˜ ì ìš© ì „ ë”í•´ì§€ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ìƒìˆ˜
        # í˜•íƒœ: (íƒ€ì„ìŠ¤í… ìˆ˜, 1) -> ê° ì‹œì ë³„ë¡œ ê³ ìœ í•œ í¸í–¥ê°’ ë¶€ì—¬
        self.b = self.add_weight(name="att_bias", 
                                 shape=(input_shape[1], 1), 
                                 initializer="zeros",
                                 trainable=True)
        
        # ê°€ì¤‘ì¹˜ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŒì„ ì„ ì–¸í•©ë‹ˆë‹¤.
        super(AttentionLayer, self).build(input_shape)

    def call(self, inputs):
        """
        ì‹¤ì œ ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ” í•µì‹¬ ë©”ì„œë“œ (Forward Propagation)
        inputs: LSTMì˜ ì¶œë ¥ê°’ (Batch, Time_steps, Feature_dim)
        """
        # [ë‹¨ê³„ 1] ì ìˆ˜ ê³„ì‚° (Score Calculation)
        # inputs(W) + b ë¥¼ í†µí•´ ê° ì‹œì ì˜ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 'ì—ë„ˆì§€ ì ìˆ˜'ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        # tanh í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ -1ê³¼ 1 ì‚¬ì´ë¡œ ë¹„ì„ í˜• ë³€í™˜í•©ë‹ˆë‹¤.
        et = tf.nn.tanh(tf.matmul(inputs, self.W) + self.b)

        # [ë‹¨ê³„ 2] í™•ë¥  ë³€í™˜ (Attention Weights)
        # Softmaxë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì‹œì ì˜ et í•©ê³„ê°€ 1(100%)ì´ ë˜ë„ë¡ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        # axis=1ì€ íƒ€ì„ìŠ¤í… ë°©í–¥ìœ¼ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì ìš©í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
        at = tf.nn.softmax(et, axis=1)

        # [ë‹¨ê³„ 3] ê°€ì¤‘ì¹˜ ì ìš© (Weight Application)
        # ì›ë³¸ ì…ë ¥ê°’(inputs)ì— ê³„ì‚°ëœ í™•ë¥  ê°€ì¤‘ì¹˜(at)ë¥¼ ê³±í•©ë‹ˆë‹¤.
        # ì¤‘ìš”í•œ ì‹œì ì˜ ë°ì´í„°ëŠ” í¬ê²Œ ë‚¨ê³ , ë¶ˆí•„ìš”í•œ ì‹œì ì€ 0ì— ê°€ê¹ê²Œ ì‘ì•„ì§‘ë‹ˆë‹¤.
        context = inputs * at

        # [ë‹¨ê³„ 4] ì •ë³´ í•©ì‚° (Context Vector)
        # ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§„ ëª¨ë“  ì‹œì ì˜ ë²¡í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤(Sum).
        # ê²°ê³¼ê°’ì€ (Batch, Feature_dim) í˜•íƒœì˜ 'ë¬¸ë§¥ ë²¡í„°'ê°€ ë©ë‹ˆë‹¤.
        # ê°€ì¤‘ì¹˜(at)ë„ ë‚˜ì¤‘ì— ì‹œê°í™”í•˜ê¸° ìœ„í•´ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.
        return tf.reduce_sum(context, axis=1), at

    def get_config(self):
        """
        ë ˆì´ì–´ì˜ ì„¤ì • ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        ì´ í•¨ìˆ˜ê°€ ìˆì–´ì•¼ model.save()ë¡œ ì €ì¥ëœ ëª¨ë¸ì„ ë‚˜ì¤‘ì— ì™„ë²½íˆ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        config = super(AttentionLayer, self).get_config()
        # ì¶”ê°€ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        return config


# 2. íŒŒì¼ ê²½ë¡œ ì„¤ì •
model_path = './model/air_passengers_best_model.h5'
scaler_path = './model/air_passengers_scaler.pkl'
data_path = './data/flights.csv'

# íŒŒì¼ ì¡´ì¬ í™•ì¸
if not all(os.path.exists(f) for f in [model_path, scaler_path, data_path]):
    print("âŒ í•„ìš”í•œ íŒŒì¼(ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ë°ì´í„°)ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    # 3. ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    # 'Custom>AttentionLayer' ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ custom_object_scopeë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    custom_objects = {'AttentionLayer': AttentionLayer}
    
    with tf.keras.utils.custom_object_scope(custom_objects):
        model = tf.keras.models.load_model(model_path, compile=False)
    
    scaler = joblib.load(scaler_path)
    print("âœ… ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")

    # 4. ì›ë³¸ ë°ì´í„° ë¡œë“œ (ë¯¸ë˜ ì˜ˆì¸¡ì˜ ê¸°ì¤€ì )
    data_df = pd.read_csv(data_path)
    col_name = 'Passengers'
    passengers = data_df[col_name].values.astype(float)

    # 5. ë¯¸ë˜ ì˜ˆì¸¡ (1961ë…„ 12ê°œì›”)
    # ë§ˆì§€ë§‰ 12ê°œì›”ì˜ ì°¨ë¶„ ë°ì´í„° ì¤€ë¹„
    seasonal_period = 12
    diff_passengers = passengers[seasonal_period:] - passengers[:-seasonal_period]
    diff_scaled = scaler.transform(diff_passengers.reshape(-1, 1))
    
    # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ (1960ë…„ íŒ¨í„´)
    # Kerasì˜ LSTM ì…ë ¥ ê·œê²©ì¸ **(Samples, Time_steps, Features)**ì— ë§ì¶°ì§„ êµ¬ì¡°ë¡œ ì¤€ë¹„í•©ë‹ˆë‹¤.
    current_batch = diff_scaled[-12:].reshape(1, 12, 1)
    
    future_diff_preds = []
    print("ğŸ”® 1961ë…„ ë¯¸ë˜ ì˜ˆì¸¡ ì§„í–‰ ì¤‘...")
    
    for i in range(12):
        pred_scaled = model.predict(current_batch, verbose=0)
        future_diff_preds.append(pred_scaled[0, 0])
        
        # ìœˆë„ìš° ìŠ¬ë¼ì´ë”© ì—…ë°ì´íŠ¸
        new_val = pred_scaled.reshape(1, 1, 1)
        current_batch = np.append(current_batch[:, 1:, :], new_val, axis=1)

    # 6. ì—­ë³€í™˜ ë° ë³µì›
    future_diff_unscaled = scaler.inverse_transform(np.array(future_diff_preds).reshape(-1, 1)).flatten()
    
    # 1961ë…„ ìµœì¢…ê°’ = 1960ë…„ ì‹¤ì œê°’ + ì˜ˆì¸¡ëœ ì¦ê°ëŸ‰
    last_year_1960 = passengers[-12:]
    forecast_1961 = last_year_1960 + future_diff_unscaled

    # 7. ì‹œê°í™” ë° ì¶œë ¥
    future_months = pd.date_range(start='1961-01-01', periods=12, freq='MS')
    forecast_series = pd.Series(forecast_1961, index=future_months)

    plt.figure(figsize=(12, 6))
    plt.plot(pd.to_datetime(data_df['Month'])[-24:], passengers[-24:], label='ì‹¤ì œê°’ (1959-1960)', marker='o')
    plt.plot(forecast_series, label='ì˜ˆì¸¡ê°’ (1961)', marker='x', color='red', linestyle='--')
    plt.title('í•­ê³µê¸° ìŠ¹ê° ìˆ˜ ë¯¸ë˜ ì˜ˆì¸¡ (1961ë…„)')
    plt.ylabel('ìŠ¹ê° ìˆ˜')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    print("\n--- 1961ë…„ ì˜ˆì¸¡ ê²°ê³¼ ---")
    for month, val in zip(future_months, forecast_1961):
        print(f"{month.strftime('%Y-%m')}: {int(val)}ëª…")