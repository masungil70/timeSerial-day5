# 딥러닝 모델 개발 단계

딥러닝 모델을 만드는 과정은 마치 **'학생에게 교과서를 주고 공부를 시켜 시험 문제를 풀게 하는 과정'** 과 매우 유사합니다. 단순히 코드를 짜는 것을 넘어, 데이터를 준비하고 학습시키는 일련의 파이프라인 형태로 진행합니다.

전체적인 흐름은 다음과 같은 **5단계**로 요약할 수 있습니다.

1. **데이터 준비 (Data Collection & Preprocessing)**
2. **모델 구조 설계 (Architecture Design)**
3. **학습 (Training)**
4. **평가 및 튜닝 (Evaluation & Hyperparameter Tuning)**
5. **저장 및 내보내기 (Export)**

---

## 1. 데이터 준비 (Data Collection & Preprocessing)

딥러닝에서 데이터는 곧 모델의 성능입니다. 양질의 데이터를 모으고 컴퓨터가 이해할 수 있는 형태로 가공해야 합니다.

* **데이터 수집:** 이미지, 텍스트, 수치 등 해결하려는 문제에 맞는 데이터를 모읍니다.
* **라벨링(Labeling):** 정답지(Target)를 달아줍니다. (예: 고양이 사진에 '고양이'라고 태그 달기)
* **전처리:** 데이터의 크기를 맞추거나(Resize), 노이즈를 제거하고, 데이터의 범위를 일정하게 맞춥니다(Normalization).

---

## 2. 모델 구조 설계 (Architecture Design)

문제의 특성에 맞는 '인공 신경망'의 구조를 결정하는 단계입니다.

* **이미지 인식:** 주로 **CNN**(Convolutional Neural Networks)을 사용합니다.
* **자연어 처리/시계열:** **RNN**이나 **Transformer**(GPT의 기반) 구조를 사용합니다.
* **프레임워크 선택:** PyTorch, TensorFlow 같은 라이브러리를 사용해 층(Layer)을 쌓습니다.

---

## 3. 학습 (Training)

모델이 데이터로부터 패턴을 배우는 단계입니다.

* **손실 함수(Loss Function):** 모델의 예측값과 실제 정답이 얼마나 다른지 계산합니다.
* **최적화(Optimizer):** 손실을 줄이기 위해 모델 내부의 가중치($w$)를 미세하게 수정합니다. (예: Adam, SGD 등)
* 이 과정을 수천, 수만 번 반복하며 모델은 점차 정답에 가까워집니다.

---

## 4. 평가 및 튜닝 (Evaluation & Hyperparameter Tuning)

학습이 끝난 모델이 '처음 보는 데이터'도 잘 맞추는지 확인합니다.

* **검증(Validation):** 학습에 쓰지 않은 별도의 데이터를 넣어 성능을 확인합니다.
* **하이퍼파라미터 튜닝:** 학습 속도(Learning Rate), 층의 개수, 뉴런 수 등을 조정하며 최적의 성능을 찾아냅니다.

---

## 5. 저장 및 내보내기 (Export)

만족스러운 성능이 나오면, 나중에 꺼내 쓸 수 있도록 파일 형태로 저장합니다.

* **파일 형식:** `.pth` (PyTorch), `.h5` (TensorFlow), 혹은 플랫폼에 구애받지 않는 표준 형식인 `.onnx` 등으로 저장합니다.

---

## 6. 딥러닝 파이프라인 vs 일반 함수 비교

딥러닝의 복잡한 5단계 과정을 우리가 흔히 사용하는 **'함수(Function)의 정의와 호출'** 관점에서 비교해 보겠습니다. 이 비유를 통해 보면 딥러닝이 결국은 "데이터를 통해 최적의 함수를 찾아내는 과정"이라는 것을 쉽게 이해할 수 있습니다.

---

### 요약 비교

| 단계 | 일반적인 함수 사용 (Programming) | 딥러닝 모델 개발 (Learning) | 비유 (학습 과정) |
| --- | --- | --- | --- |
| **1. 데이터 준비** | 함수의 **매개변수(인자)** 정의 및 입력값 준비 | **학습 데이터(Feature/Label)** 수집 및 정규화 | 교과서와 정답지 마련 |
| **2. 모델 설계** | 함수의 **본문(Logic)** 을 직접 코딩 | 함수의 **구조(Layer/Node)** 만 결정 (내용은 빈칸) | 공부할 학생의 뇌 구조 설정 |
| **3. 학습** | (해당 사항 없음 - 로직이 고정됨) | 데이터를 반복 주입하여 **파라미터(W, b)** 최적화 | 교과서 무한 반복 및 오답 노트 작성 |
| **4. 평가 및 튜닝** | 테스트 케이스 실행 및 디버깅 | **검증 데이터** 로 정확도 확인 및 설정(LR 등) 변경 | 모의고사 풀기 및 공부 방법 수정 |
| **5. 저장 및 내보내기** | 코드 저장 및 라이브러리 배포 | 완성된 **가중치(Weight) 파일** 저장 | 졸업 및 실전 투입 |

---

### 상세 비교 설명

#### 1. 데이터 준비 ( 관계 설정)

* **일반 함수**: `def add(a, b):` 처럼 어떤 값이 들어올지 형식을 정합니다.
* **딥러닝**: 데이터의 형태(Shape)를 맞추고, 모델이 공부하기 좋게 숫자를 보정합니다(Scaling).

#### 2. 모델 구조 설계 (빈 상자 만들기)

* **일반 함수**: `return a + b` 처럼 사람이 직접 **규칙(Rule)**을 작성합니다.
* **딥러닝**: `Dense`, `Conv2d` 등을 쌓아 구조를 만듭니다. 이때 함수 내부의 구체적인 수식(가중치)은 비어있는 **'지능형 빈 상자'** 상태입니다.

#### 3. 학습 (함수 스스로 로직 채우기) 💡 **핵심 차이**

* **일반 함수**: 학습 단계가 없습니다. 사람이 작성한 대로만 움직입니다.
* **딥러닝**: 수만 번의 문제를 풀며 `a + b`를 할지 `a * b`를 할지, 혹은 그보다 복잡한 계산을 할지 모델 스스로 내부 수치(가중치)를 채워 나갑니다.

#### 4. 평가 및 튜닝 (성능 검증)

* **일반 함수**: 에러가 나면 사람이 코드를 직접 고칩니다.
* **딥러닝**: 성적이 안 나오면 '공부 속도(Learning Rate)'를 조절하거나 '더 똑똑한 뇌 구조(Architecture)'로 바꿉니다.

#### 5. 저장 및 내보내기 (함수 사용하기)

* **일반 함수**: 완성된 코드를 호출하여 사용합니다.
* **딥러닝**: 학습이 끝난 모델(함수)을 `.h5`나 `.pt` 파일로 저장합니다. 이제 이 파일은 어떤 입력값이 들어와도 정답을 추론할 수 있는 **'완성된 공식'** 이 됩니다.

---

## 모델 제작을 위한 간단한 로드맵

| 단계 | 도구 및 기술 | 비유 |
| --- | --- | --- |
| **데이터** | Pandas, Numpy, OpenCV | 교과서 준비 및 요약 |
| **설계/학습** | PyTorch, TensorFlow, Keras | 학생(AI)에게 공부시키기 |
| **평가** | Scikit-learn, TensorBoard | 모의고사 치르기 |
| **최종본** | ONNX, SavedModel | 졸업 및 취업 준비 |
